[
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "SYLLABUS 2024",
    "section": "",
    "text": "Barrie D. Robison\nFall 2024\n\n\nStudents are taught writing and presentation skills to improve their communication of data-driven insights to specialist and lay audiences. The course emphasizes reproducible research practices, including literate programming (Quarto / Markdown) and version control (GitHub). Course content includes the conceptual foundations of communicating with data along with written and verbal assignments using data sets individualized to each student’s interest. The course is designed to be “discipline agnostic” - each student is encouraged to use their own data, or public data sets that they deem important / interesting.\n\n\n\nStudents completing this course will be able to:\n\nIdentify, understand, and describe the critical characteristics, needs, and expectations of the various audiences with whom they will communicate.\nDevelop and apply effective writing and presentation skills to communicate data-driven insights clearly and impactfully to both specialist and general audiences.\nImplement reproducible research practices using literate programming (Quarto/Markdown) and version control (GitHub) to enhance the transparency and reproducibility of their work.\nCreate compelling narratives around data that are tailored to specific disciplines while remaining accessible to interdisciplinary audiences.\nCritically evaluate and apply appropriate data visualization techniques to support written and verbal communications, enhancing the accessibility of complex data analysis results.\n\n\n\n\nAs assigned. There is not a required textbook for this class.\n\n\n\n\n\n40% of your grade will be determined by homework exercises related to each course unit.\n20% of your grade will be determined by a mid term project (which would be a great item to include in your Data Science Portfolio).\n20% of your grade will be determined by a final project (which would be great item to include in your Data Science Portfolio).\n20% of your grade will be determined by participation in class discussions and individual meetings with the instructor.\nGRADING SCALE: The grading scale is standard: A (90 -100 %), B (89 - 80 %), C (79 - 70 %), D (69-60 %), F( below 60 %).\n\n\n\nMissing a scheduled class session is at your discretion. I will be posting all the course materials online. If a discussion or in-class exercise occurs and you miss it, you will lose those participation points. There is no way to make up those points.\n\n\n\nThe R Markdown template I used for this syllabus was created by Dr. Steven V. Miller at Stockholm University. It contained this section, which I found amusing and have therefore retained. Professor Miller’s current university asks professors to have policies written into their syllabus about what students should do if the professor is more than 15 minutes late to class. Here is my version of that policy:\nI will inform students via e-mail in advance of class if class is cancelled for the day. Events that might create such a scenario include travel obligations that emerged after the semester has begun, a family emergency that encompasses multiple days, or some other thing. I will also contact our department secretary in emergent situations, such as something happening on the way to work. Failing that, assume the worst. Alien abduction, the return of one or more Old Ones to our plane, or some kind of attack by wizards are all viable explanations for my inability to attend class. I ask that the students make sure that my story gets the proper treatment on the “Mr. Ballen” YouTube channel. I also ask that my story be narrated by Morgan Freeman and that the role of me in the made for TV movie be played by Keanu Reeves or Danny DeVito.\n\n\n\nThe bad news is that there are NO make-ups for missed exams. Don’t bother asking. The good news is that there aren’t any exams.\n\n\n\nAll students are expected to uphold the highest standards of academic honesty. This includes but is not limited to: not cheating, not using the ideas of others without giving appropriate credit (including AI tools), and not falsifying data. Any incident of academic dishonesty will be handled according to the guidelines of the University of Idaho.\n\n\n\n\n\nlibrary(readxl)\nSchedule &lt;- read_excel(\"Schedule.xlsx\")\n\nknitr::kable(Schedule, caption = '')\n\n\n\n\nDATE\nTOPIC\nACTIVITY\nRESOURCES\n\n\n\n\n2024-08-20\nNO CLASS THIS WEEK\nBarrie moves his son to Syracuse\nWhiskey?\n\n\n2024-08-22\nNO CLASS THIS WEEK\nBarrie moves his son to Syracuse\nEndless patience?\n\n\n2024-08-27\nIntroduction\nIn Class Discussion\nCourse Website\n\n\n2024-08-29\nWork Day (R Studio and Quarto)\nAssignment 1\nTutorial\n\n\n2024-09-03\nYour Data\nAssigment 2\nNA\n\n\n2024-09-05\nWork Day (Data cleaning and exploration)\nNA\nNA\n\n\n2024-09-10\nVersion Control\nNA\nNA\n\n\n2024-09-12\nWork Day (The Abyss of Github)\nNA\nNA\n\n\n2024-09-17\nNA\nNA\nNA\n\n\n2024-09-19\nNA\nNA\nNA\n\n\n2024-09-24\nBARRIE IN ABQ\nNA\nNA\n\n\n2024-09-26\nNA\nNA\nNA\n\n\n2024-10-01\nBARRIE AT UCF\nNA\nNA\n\n\n2024-10-03\nBARRIE AT UCF\nNA\nNA\n\n\n2024-10-08\nNA\nNA\nNA\n\n\n2024-10-10\nNA\nNA\nNA\n\n\n2024-10-15\nNA\nNA\nNA\n\n\n2024-10-17\nNA\nNA\nNA\n\n\n2024-10-22\nNA\nNA\nNA\n\n\n2024-10-24\nNA\nNA\nNA\n\n\n2024-10-29\nNA\nNA\nNA\n\n\n2024-10-31\nNA\nNA\nNA\n\n\n2024-11-05\nNA\nNA\nNA\n\n\n2024-11-07\nNA\nNA\nNA\n\n\n2024-11-12\nNA\nNA\nNA\n\n\n2024-11-14\nNA\nNA\nNA\n\n\n2024-11-19\nNA\nNA\nNA\n\n\n2024-11-21\nNA\nNA\nNA\n\n\n2024-11-26\nFALL RECESS\nNA\nNA\n\n\n2024-11-28\nFALL RECESS\nNA\nNA\n\n\n2024-12-03\nDEAD WEEK\nNA\nNA\n\n\n2024-12-05\nDEAD WEEK\nNA\nNA\n\n\n2024-12-10\nFINAL EXAMS\nNA\nNA\n\n\n2024-12-12\nFINAL EXAMS\nNA\nNA"
  },
  {
    "objectID": "syllabus.html#course-description",
    "href": "syllabus.html#course-description",
    "title": "SYLLABUS 2024",
    "section": "",
    "text": "Students are taught writing and presentation skills to improve their communication of data-driven insights to specialist and lay audiences. The course emphasizes reproducible research practices, including literate programming (Quarto / Markdown) and version control (GitHub). Course content includes the conceptual foundations of communicating with data along with written and verbal assignments using data sets individualized to each student’s interest. The course is designed to be “discipline agnostic” - each student is encouraged to use their own data, or public data sets that they deem important / interesting."
  },
  {
    "objectID": "syllabus.html#course-objectives",
    "href": "syllabus.html#course-objectives",
    "title": "SYLLABUS 2024",
    "section": "",
    "text": "Students completing this course will be able to:\n\nIdentify, understand, and describe the critical characteristics, needs, and expectations of the various audiences with whom they will communicate.\nDevelop and apply effective writing and presentation skills to communicate data-driven insights clearly and impactfully to both specialist and general audiences.\nImplement reproducible research practices using literate programming (Quarto/Markdown) and version control (GitHub) to enhance the transparency and reproducibility of their work.\nCreate compelling narratives around data that are tailored to specific disciplines while remaining accessible to interdisciplinary audiences.\nCritically evaluate and apply appropriate data visualization techniques to support written and verbal communications, enhancing the accessibility of complex data analysis results."
  },
  {
    "objectID": "syllabus.html#required-readings",
    "href": "syllabus.html#required-readings",
    "title": "SYLLABUS 2024",
    "section": "",
    "text": "As assigned. There is not a required textbook for this class."
  },
  {
    "objectID": "syllabus.html#course-policies",
    "href": "syllabus.html#course-policies",
    "title": "SYLLABUS 2024",
    "section": "",
    "text": "40% of your grade will be determined by homework exercises related to each course unit.\n20% of your grade will be determined by a mid term project (which would be a great item to include in your Data Science Portfolio).\n20% of your grade will be determined by a final project (which would be great item to include in your Data Science Portfolio).\n20% of your grade will be determined by participation in class discussions and individual meetings with the instructor.\nGRADING SCALE: The grading scale is standard: A (90 -100 %), B (89 - 80 %), C (79 - 70 %), D (69-60 %), F( below 60 %).\n\n\n\nMissing a scheduled class session is at your discretion. I will be posting all the course materials online. If a discussion or in-class exercise occurs and you miss it, you will lose those participation points. There is no way to make up those points.\n\n\n\nThe R Markdown template I used for this syllabus was created by Dr. Steven V. Miller at Stockholm University. It contained this section, which I found amusing and have therefore retained. Professor Miller’s current university asks professors to have policies written into their syllabus about what students should do if the professor is more than 15 minutes late to class. Here is my version of that policy:\nI will inform students via e-mail in advance of class if class is cancelled for the day. Events that might create such a scenario include travel obligations that emerged after the semester has begun, a family emergency that encompasses multiple days, or some other thing. I will also contact our department secretary in emergent situations, such as something happening on the way to work. Failing that, assume the worst. Alien abduction, the return of one or more Old Ones to our plane, or some kind of attack by wizards are all viable explanations for my inability to attend class. I ask that the students make sure that my story gets the proper treatment on the “Mr. Ballen” YouTube channel. I also ask that my story be narrated by Morgan Freeman and that the role of me in the made for TV movie be played by Keanu Reeves or Danny DeVito.\n\n\n\nThe bad news is that there are NO make-ups for missed exams. Don’t bother asking. The good news is that there aren’t any exams.\n\n\n\nAll students are expected to uphold the highest standards of academic honesty. This includes but is not limited to: not cheating, not using the ideas of others without giving appropriate credit (including AI tools), and not falsifying data. Any incident of academic dishonesty will be handled according to the guidelines of the University of Idaho."
  },
  {
    "objectID": "syllabus.html#class-schedule",
    "href": "syllabus.html#class-schedule",
    "title": "SYLLABUS 2024",
    "section": "",
    "text": "library(readxl)\nSchedule &lt;- read_excel(\"Schedule.xlsx\")\n\nknitr::kable(Schedule, caption = '')\n\n\n\n\nDATE\nTOPIC\nACTIVITY\nRESOURCES\n\n\n\n\n2024-08-20\nNO CLASS THIS WEEK\nBarrie moves his son to Syracuse\nWhiskey?\n\n\n2024-08-22\nNO CLASS THIS WEEK\nBarrie moves his son to Syracuse\nEndless patience?\n\n\n2024-08-27\nIntroduction\nIn Class Discussion\nCourse Website\n\n\n2024-08-29\nWork Day (R Studio and Quarto)\nAssignment 1\nTutorial\n\n\n2024-09-03\nYour Data\nAssigment 2\nNA\n\n\n2024-09-05\nWork Day (Data cleaning and exploration)\nNA\nNA\n\n\n2024-09-10\nVersion Control\nNA\nNA\n\n\n2024-09-12\nWork Day (The Abyss of Github)\nNA\nNA\n\n\n2024-09-17\nNA\nNA\nNA\n\n\n2024-09-19\nNA\nNA\nNA\n\n\n2024-09-24\nBARRIE IN ABQ\nNA\nNA\n\n\n2024-09-26\nNA\nNA\nNA\n\n\n2024-10-01\nBARRIE AT UCF\nNA\nNA\n\n\n2024-10-03\nBARRIE AT UCF\nNA\nNA\n\n\n2024-10-08\nNA\nNA\nNA\n\n\n2024-10-10\nNA\nNA\nNA\n\n\n2024-10-15\nNA\nNA\nNA\n\n\n2024-10-17\nNA\nNA\nNA\n\n\n2024-10-22\nNA\nNA\nNA\n\n\n2024-10-24\nNA\nNA\nNA\n\n\n2024-10-29\nNA\nNA\nNA\n\n\n2024-10-31\nNA\nNA\nNA\n\n\n2024-11-05\nNA\nNA\nNA\n\n\n2024-11-07\nNA\nNA\nNA\n\n\n2024-11-12\nNA\nNA\nNA\n\n\n2024-11-14\nNA\nNA\nNA\n\n\n2024-11-19\nNA\nNA\nNA\n\n\n2024-11-21\nNA\nNA\nNA\n\n\n2024-11-26\nFALL RECESS\nNA\nNA\n\n\n2024-11-28\nFALL RECESS\nNA\nNA\n\n\n2024-12-03\nDEAD WEEK\nNA\nNA\n\n\n2024-12-05\nDEAD WEEK\nNA\nNA\n\n\n2024-12-10\nFINAL EXAMS\nNA\nNA\n\n\n2024-12-12\nFINAL EXAMS\nNA\nNA"
  },
  {
    "objectID": "posts/A3-YourData/index.html",
    "href": "posts/A3-YourData/index.html",
    "title": "ASSIGNMENT 3 - Your Data.",
    "section": "",
    "text": "A key feature of this course is that students should be using their own data whenever possible. This is critical to forging a learning experience that is customized to each student’s aspirations and the eccentricities of their chosen research domain. This assignment begins the process of helping you identify the data sets with which you want to work, and aligns with the notion of understanding your audience(s) and your communication goal(s)."
  },
  {
    "objectID": "posts/A3-YourData/index.html#summary",
    "href": "posts/A3-YourData/index.html#summary",
    "title": "ASSIGNMENT 3 - Your Data.",
    "section": "",
    "text": "A key feature of this course is that students should be using their own data whenever possible. This is critical to forging a learning experience that is customized to each student’s aspirations and the eccentricities of their chosen research domain. This assignment begins the process of helping you identify the data sets with which you want to work, and aligns with the notion of understanding your audience(s) and your communication goal(s)."
  },
  {
    "objectID": "posts/A3-YourData/index.html#assignment",
    "href": "posts/A3-YourData/index.html#assignment",
    "title": "ASSIGNMENT 3 - Your Data.",
    "section": "ASSIGNMENT",
    "text": "ASSIGNMENT\nThe basic structure of this assignment is for you to identify, import, describe, and host a data set. I’ll break down the specifics for each of these actions below.\n\nIdentify a Data Set\nThe main criteria is that the data set has to matter to you in some way. Often, this will mean that it is your data set. It was collected by you and has a central role in your current or past graduate research. Awesome! Another scenario is that the data you want to use comes from your current job. Maybe it isn’t part of a research project, but you are motivated to learn how to work with the data or you are very interested in learning more about it. Also Awesome!\nSome of you might not have your own data. Perhaps you have just started your graduate training. Maybe your job doesn’t yet have data that you need to work with. No Problem!\nIt is perfectly fine to find publicly available data sets online. As long as the data set is interesting to you! You just need to make sure that the data:\n\nAre publicly available.\nAre not restricted by some kind of license or copyright.\nDo not contain private information.\nAre not covered by HIPPA, FERPA, CMMC, or other federal regulations related to data.\n\nIf you need help finding a data set, just let me know.\nSome fun potential categories for data sources include:\n\nSports Analytics from your favorite sport or team.\nPublicly available genomics data bases.\nKeggle.\nThe movie data base.\nClassic data sets from your field.\n\n\n\nImport the Data Set\nThis one is probably straightforward if your data set comes from your own research and lives on your local hard drive already.\n\n\nDescribe the Data Set\nThis is the bulk of the assignment. I want you to use the framework described in Dr. Munzner’s textbook to understand your data set and describe it to someone who is unfamiliar with your work. The basis of this approach is described in this figure from the textbook I use in BCB 520. It summarizes the kinds of data types, data set types, and attribute types you might have in your data:\n\n\n\nHost your Data Set\nUltimately, we are moving toward each of you hosting your assignments within an online repository that can serve as your data science portfolio. For this course, we are going to assume this is GitHub. Create a new blog post for this assignment\n\n\nConsider a Communication Scenario\nLet’s start with a 5 minute presentation to the class. Due… I don’t know… One week from today (Tuesday September 17, 2024). I want a five minute presentation that uses your data. At the beginning of the presentation, I want you to clearly specify:\n\nThe characteristics of your audience that you consider important, and for which you must prepare.\nYour goals for the presentation. I’d like one overarching (or longer term), one communication goal, and one more goal that you are free to specify. Have a look at the lists from the previous lecture for inspiration."
  },
  {
    "objectID": "posts/A3-YourData/index.html#resources",
    "href": "posts/A3-YourData/index.html#resources",
    "title": "ASSIGNMENT 3 - Your Data.",
    "section": "RESOURCES",
    "text": "RESOURCES\nA YouTube Video from Posit on Building your Data Science Portfolio\nA fun Spotify example from TidyTuesday by Kaylin Pavlik."
  },
  {
    "objectID": "posts/T1-Lit-Prog/index.html",
    "href": "posts/T1-Lit-Prog/index.html",
    "title": "TUTORIAL 1 - Literate Programming",
    "section": "",
    "text": "Learning new tools is hard. Plowing though the tomes of the Data Science Mythos is hard. Perhaps this tutorial will guide you through the mind shattering truths of… LITERATE PROGRAMMING."
  },
  {
    "objectID": "posts/T1-Lit-Prog/index.html#intro-to-quarto",
    "href": "posts/T1-Lit-Prog/index.html#intro-to-quarto",
    "title": "TUTORIAL 1 - Literate Programming",
    "section": "",
    "text": "Learning new tools is hard. Plowing though the tomes of the Data Science Mythos is hard. Perhaps this tutorial will guide you through the mind shattering truths of… LITERATE PROGRAMMING."
  },
  {
    "objectID": "posts/A1-Lit-Prog/index.html",
    "href": "posts/A1-Lit-Prog/index.html",
    "title": "ASSIGNMENT 1 - Fun with literate programming.",
    "section": "",
    "text": "The idea of Literate Programming is that source code that is executed as part of the program’s purpose is interspersed with documentation that describes the program’s logic. The concept of literate programming was first articulated by David Knuth in 1984. You know… back when music was good? Modern Data Science leans pretty heavily on literate programming, and to be honest, there aren’t very many good arguments as to why you WOULDN’T want to implement this approach in your own work. Bearing this in mind, we will adopt this framework for most of the activities, exercises, and assignments in this course. All of us will benefit by practicing these skills."
  },
  {
    "objectID": "posts/A1-Lit-Prog/index.html#summary",
    "href": "posts/A1-Lit-Prog/index.html#summary",
    "title": "ASSIGNMENT 1 - Fun with literate programming.",
    "section": "",
    "text": "The idea of Literate Programming is that source code that is executed as part of the program’s purpose is interspersed with documentation that describes the program’s logic. The concept of literate programming was first articulated by David Knuth in 1984. You know… back when music was good? Modern Data Science leans pretty heavily on literate programming, and to be honest, there aren’t very many good arguments as to why you WOULDN’T want to implement this approach in your own work. Bearing this in mind, we will adopt this framework for most of the activities, exercises, and assignments in this course. All of us will benefit by practicing these skills."
  },
  {
    "objectID": "posts/A1-Lit-Prog/index.html#literate-programming-publishing-systems",
    "href": "posts/A1-Lit-Prog/index.html#literate-programming-publishing-systems",
    "title": "ASSIGNMENT 1 - Fun with literate programming.",
    "section": "LITERATE PROGRAMMING PUBLISHING SYSTEMS",
    "text": "LITERATE PROGRAMMING PUBLISHING SYSTEMS\nI’m trying to keep this course as technology agnostic as I can. The idea is that you should be practicing and building competencies in the languages and algorithms that are most useful to you. Who am I to tell you to use R instead of Python? If you have skills in a particular language I encourage you to keep using that during this course. That being said, I am going to work the examples using R and R Studio, and I will (mostly) use Quarto as the literate programming framework.\nIf all of this is new to you, no problem. Just follow along in R and Quarto and start your skill building journey with those languages.\nIf you are a Python person, great! Quarto can accommodate that language as well. If you have another preference for literate programming, such as sticking with R Markdown until the Quarto bugs are fixed, that is great. Find the framework and tools that work for you, and practice, practice, practice!\n\nQuarto\nAn open source publishing system that allows you to create websites, documents, blogs, books, publications, presentations, and more while using R, Python, Julia, or Observable. Quarto is intended to be the more functional successor of R Markdown. I intend to use Quarto for most of my work in this course.\n\n\nR Markdown\nAnother publishing system for creating all the things … websites, slides, manuscripts, dashboards, etc. While most people (including me!) instinctively think of R and Python within R Markdown, the list of supported language engines is pretty extensive.\n\nnames(knitr::knit_engines$get())\n\n [1] \"awk\"       \"bash\"      \"coffee\"    \"gawk\"      \"groovy\"    \"haskell\"  \n [7] \"lein\"      \"mysql\"     \"node\"      \"octave\"    \"perl\"      \"php\"      \n[13] \"psql\"      \"Rscript\"   \"ruby\"      \"sas\"       \"scala\"     \"sed\"      \n[19] \"sh\"        \"stata\"     \"zsh\"       \"asis\"      \"asy\"       \"block\"    \n[25] \"block2\"    \"bslib\"     \"c\"         \"cat\"       \"cc\"        \"comment\"  \n[31] \"css\"       \"ditaa\"     \"dot\"       \"embed\"     \"eviews\"    \"exec\"     \n[37] \"fortran\"   \"fortran95\" \"go\"        \"highlight\" \"js\"        \"julia\"    \n[43] \"python\"    \"R\"         \"Rcpp\"      \"sass\"      \"scss\"      \"sql\"      \n[49] \"stan\"      \"targets\"   \"tikz\"      \"verbatim\"  \"ojs\"       \"mermaid\""
  },
  {
    "objectID": "posts/A1-Lit-Prog/index.html#languages-and-toolsets",
    "href": "posts/A1-Lit-Prog/index.html#languages-and-toolsets",
    "title": "ASSIGNMENT 1 - Fun with literate programming.",
    "section": "LANGUAGES AND TOOLSETS",
    "text": "LANGUAGES AND TOOLSETS\nThere are quite a few, but the five that seemed to keep coming up as I prepped this course are:\n\nR\nA very powerful open source framework for statistical computing and graphics. R has a lot of base functionality, and its capabilities are increased by 100 fold with packages created by R users. Packages are the core units of R code. I’m going to use R for the vast majority of demonstrations in this course.\n\n\nPython\nPython is an open source general purpose programming language. It wasn’t developed just for statistical computing or data science, and people use this language for tons of different applications. There is no denying it has become a very powerful language for data science and data visualization.\n\n\nTableau\nTableau is proprietary software that is very powerful for creating beautiful and functional data visualizations. It can integrate with all sorts of data sources and is used a lot for analytics, especially in the business world. The downsides (that occur to me at least) are that it costs money, it is not open source, and is more of a one-trick-pony than the programming languages on this list. It may be a great tool in your communication tool kit, but you will need to use additional things for communication tasks that go beyond “showing” into speaking and writing.\n\n\nJavascript\nJavascript has been around for about 25 years, and is (I think) the world’s most popular programming language. Along with HTML and CSS, Javascript drives pretty much the entire internet. I mention Javascript here because it has the D3 library, which can create super cool interactive data visualizaitons. In my experience, the learning curve with Javascript and D3 was pretty steep. I bought a book about it once, but just haven’t been able to allocate the amount of time necessary to really start using it. Check out the gallery of examples. Amazing!\n\n\nObservable / D3\nObservable is a set of extensions to Javascript that features something called reactive runtime. This means that the code blocks are executed and compiled as they are written, and changes are implemented instantaneously. Observable is pretty great for data exploration, and is well supported by Quarto. In addition, you can use the Observable JS libraries in Quarto to access D3. We’ll use some of these tools in this course, especially when we start considering interactivity."
  },
  {
    "objectID": "posts/A1-Lit-Prog/index.html#assignment",
    "href": "posts/A1-Lit-Prog/index.html#assignment",
    "title": "ASSIGNMENT 1 - Fun with literate programming.",
    "section": "ASSIGNMENT",
    "text": "ASSIGNMENT\nAfter that long introduction, I suppose you are wondering what I want you to actually DO today.\nWell, I want you to set up your publishing system and preferred language on your computer. Then I want you to create a quarto project and render an html page.\nNow, you might be asking…\n“How am I supposed to do that? You haven’t taught me how to do anything yet!”\nHere is the dirty little secret of modern education.\nThe Internet Exists.\nWhile I could use up an entire 50 minute lecture telling you how to:\n\nDownload and install R, R-Studio, and Quarto (included by default with R-Studio).\nCreate a Quarto document that will publish in the .html format\n\nI’m not going to do that.\nInstead, I want you to use the resources I point towards, or other resources that make more sense to you, to figure out how to do those things."
  },
  {
    "objectID": "posts/A1-Lit-Prog/index.html#resources",
    "href": "posts/A1-Lit-Prog/index.html#resources",
    "title": "ASSIGNMENT 1 - Fun with literate programming.",
    "section": "RESOURCES",
    "text": "RESOURCES\nHandy cheat-sheets for many different R packages\nTutorial 1 - Literate Programming"
  },
  {
    "objectID": "posts/T2_CodeComm/CodeComm.html",
    "href": "posts/T2_CodeComm/CodeComm.html",
    "title": "Tutorial 2 - Communicating with Code",
    "section": "",
    "text": "The purpose of this post is to provide some example data visualizations that can be presented to the player of our new evolutionary video game, Shep.Herd. The game features a generational evolutionary model, and between each generation the player can earn bonus resources if they correctly answer a data literacy question.\nThe visualizations are separated by milestones related to game progress. Some visualizations are not informative until the player has progressed through more than 5 generations."
  },
  {
    "objectID": "posts/T2_CodeComm/CodeComm.html#assessing-data-science-literacy-in-shep.herd",
    "href": "posts/T2_CodeComm/CodeComm.html#assessing-data-science-literacy-in-shep.herd",
    "title": "Tutorial 2 - Communicating with Code",
    "section": "",
    "text": "The purpose of this post is to provide some example data visualizations that can be presented to the player of our new evolutionary video game, Shep.Herd. The game features a generational evolutionary model, and between each generation the player can earn bonus resources if they correctly answer a data literacy question.\nThe visualizations are separated by milestones related to game progress. Some visualizations are not informative until the player has progressed through more than 5 generations."
  },
  {
    "objectID": "posts/T2_CodeComm/CodeComm.html#reading-in-the-data",
    "href": "posts/T2_CodeComm/CodeComm.html#reading-in-the-data",
    "title": "Tutorial 2 - Communicating with Code",
    "section": "Reading in the data",
    "text": "Reading in the data\nFor the purposes of this example, I’m using a data file called newdata4.csv from a single run of the game.\n\n\nCode\ndf = pd.read_csv('newdata4.csv')\n\ndf_wave_0 = df[df['Wave Number'] == 0] # Some visualizations will focus only on the first generation (wave 0)\n\ndf_wave_4 = df[df['Wave Number'] == 3] # Some visualizations will focus only on generations between 0 and 4 so we will use generation 3 as an example.\n\n\nEach dataframe features 27 columns, and 300 observations per generation (one observation per enemy in the population). The columns define a variety of traits and genes that are potenially under selection by the player’s defenses. There are also metadata related to the enemy ID, its parents, and the number of offspring it contributed to the next generation (that the player is about to face)."
  },
  {
    "objectID": "posts/T2_CodeComm/CodeComm.html#after-generation-0",
    "href": "posts/T2_CodeComm/CodeComm.html#after-generation-0",
    "title": "Tutorial 2 - Communicating with Code",
    "section": "After Generation 0",
    "text": "After Generation 0\nAfter defeating the first generation, the player could be shown graphs summarizing a limited set of traits. These could include Speed, Tower Atraction, Slime Attraction, and Turn Rate. The two types of visualizations at this stage could be Histograms or Scatterplots. The tabsets below show examples of these plots, and each is accompanied by some questions that could be used in the game to assess player data literacy.\n\nTrait HistogramsScatterplots\n\n\n\n\nCode\n# Define bin edges\nbin_edges = np.arange(0, 12.5, 0.5)\n\n# Create a histogram using plotly with custom bins\n# Note that my choice of the Speed Trait here was arbitrary.  I could have used other traits from the list.\n\nfig = go.Figure(data=[go.Histogram(\n    x=df_wave_0['Speed Trait'],\n    xbins=dict(\n        start=0,\n        end=12,\n        size=0.5\n    ),\n    autobinx=False\n)])\n\n# Update the layout for better readability\n\nfig.update_layout(\n    title='Histogram of Speed (Wave Number = 0)',\n    xaxis_title='Speed',\n    yaxis_title='Number of Slimes',\n    bargap=0.1,\n    xaxis=dict(\n        range=[0, 12],\n        tickmode='array',\n        tickvals=list(range(0, 13)),\n        ticktext=[f\"{i:.1f}\" for i in range(0, 13)]\n    )\n)\n\n# Save the plot as an HTML file\nfig.write_html('speed_histogram.html')\n\n# This will allow us to display the plot in Quarto\nfig.show()\n\n\n                                                \n\n\n\nWhat is the correct name for this type of graph?\n\nA. Scatterplot\nB. Histogram\nC. Regression Line\nD. Time Series\n\n\n\n\nClick to see the answer\n\nAnswer: B. Histogram\nExplanation: A Histogram is a special type of bar chart that shows the frequency distribution of another variable.\n\n\nWhat is your best estimate of the range of the data for Speed?\n\nA. 1.0 to 5.5\nB. 1.0 to 5.0\nC. 0.0 to 12.0\nD. 0.0 to 109.0\n\n\n\n\nClick to see the answer\n\nAnswer: A. 1.0 to 5.5\nExplanation: Values of Speed are shown on the x axis, and the range is defined as the lowest and highest value of the variable. The lowest value of Speed is in the 1.0 bin, and the highest value is in the 5.5 bin.\n\n\nWhat bin contains the Mode of the distribution for Speed?\n\nA. 1.0 to 1.5\nB. 109 Slimes\nC. 2.0 to 2.5\nD. 6.0 to 6.5\n\n\n\n\nClick to see the answer\n\nAnswer: C. 2.0 to 2.5\nExplanation: The Mode of a distribution is its most frequently observed value. In this case, the 2.0 to 2.5 bin contains the most slimes.\n\n\n\n\n\nCode\n# Create a scatterplot using plotly.  Again, the choice of traits here is arbitrary.\nfig = px.scatter(df_wave_0, \n                 x='Speed Trait', \n                 y='Tower Attraction Trait',\n                 title='Scatterplot of Speed Trait vs Tower Attraction (Wave Number = 0)')\n\n# Update the layout for better readability\nfig.update_layout(\n    xaxis_title='Speed Trait',\n    yaxis_title='Tower Attraction Trait',\n    xaxis=dict(range=[0, 6]),  # Adjusting based on the histogram range\n)\n\n# Save the plot as an HTML file\nfig.write_html('speed_tower_scatterplot.html')\n\n# Display the plot\nfig.show()\n\n# Print some information about the filtered dataset\nprint(f\"Number of observations with Wave Number 0: {len(df_wave_0)}\")\nprint(f\"Correlation between Speed Trait and Tower Attraction Trait:\")\nprint(df_wave_0[['Speed Trait', 'Tower Attraction Trait']].corr())\n\n\n                                                \n\n\nNumber of observations with Wave Number 0: 300\nCorrelation between Speed Trait and Tower Attraction Trait:\n                        Speed Trait  Tower Attraction Trait\nSpeed Trait                1.000000                0.024498\nTower Attraction Trait     0.024498                1.000000\n\n\n\nWhat type of relationship appears to exist between Speed Trait and Tower Attraction Trait?\n\nA. Strong positive correlation\nB. Strong negative correlation\nC. Weak positive correlation\nD. No clear correlation\n\n\nClick to see the answer\n\nAnswer: D. No clear correlation Explanation: The scatterplot shows no clear pattern or trend between Speed Trait and Tower Attraction Trait, indicating no clear correlation between these variables.\n\n\nWhat is the approximate range of values for the Tower Attraction Trait?\n\nA. 0 to 6\nB. 0 to 12\nC. -6 to 6\nD. -12 to 12\n\n\nClick to see the answer\n\nAnswer: C. -6 to 6 Explanation: The y-axis of the scatterplot, which represents the Tower Attraction Trait, appears to range from approximately -6 to 6.\n\n\nOn this graph, what does each individual point (circle) represent?\n\nA. The maximum value of [Trait 1] and [Trait 2] from all previous Generations of slimes.\nB. The average values of the Traits for each slime from Generation X.\nC. The exact values of [Trait 1] and [Trait 2] for each slime from Generation X.\nD. The probability that each Slime will reproduce this generation.\n\n\nClick to see the answer\n\nAnswer: C. The exact values of [Trait 1] and [Trait 2] for each slime from Generation X. Explanation: This is a scatter plot of trait values from the previous generation. A scatterplot plots exact values for two quantitative variables (Traits) on two orthogonal axes."
  },
  {
    "objectID": "posts/T2_CodeComm/CodeComm.html#after-generation-3",
    "href": "posts/T2_CodeComm/CodeComm.html#after-generation-3",
    "title": "Tutorial 2 - Communicating with Code",
    "section": "After Generation 3",
    "text": "After Generation 3\nAfter playing the game for a few generations, additional visualizations are possible. In particular, the player will notice the emergence of different enemy types (all enemies start as basic in gen 0). The enemy types are Basic, Blaster, Ice, Fire, Laser, and Acid. The type is specified in the Main Type column.\n\nType chartsFitness Charts\n\n\nHere we introduce visualizations related to discrete data (Type) and count data (frequency).\n\n\nCode\n# Define the custom color palette.  I hated the defaults.\ncolor_palette = {\n    'Basic': '#D3D3D3',  # Light grey\n    'Blaster': '#8B0000',  # Dark reddish grey\n    'Ice': '#1E90FF',  # Blue\n    'Fire': '#FFA500',  # Orange\n    'Laser': '#800080',  # Purple\n    'Acid': '#00FF00'  # Green\n}\n\n# Count the frequency of each Main Type\nmain_type_counts = df_wave_4['Main Type'].value_counts().reset_index()\nmain_type_counts.columns = ['Main Type', 'Count']\n\n# Create a column chart using plotly with custom colors\nfig = px.bar(main_type_counts, x='Main Type', y='Count',\n             title='Distribution of Main Types (Wave Number = 4)',\n             color='Main Type',\n             color_discrete_map=color_palette)\n\n# Update the layout for better readability\nfig.update_layout(\n    xaxis_title='Main Type',\n    yaxis_title='Number of Slimes',\n    xaxis_tickangle=-45\n)\n\n# Save the plot as an HTML file\nfig.write_html('main_type_distribution_colored.html')\n\n# Display the plot\nfig.show()\n\n\n                                                \n\n\nWe should totally do a bargraph race at the end of the game! Plus other animated graphs!\n\nWhat is the correct name for this type of graph?\n\nA. Scatterplot\nB. Bar Chart\nC. Regression Line\nD. Time Series\n\n\n\n\nClick to see the answer\n\nAnswer: B. Bar Chart\nExplanation: A Bar Chart is used to represent a quantitative variable (the height of the bar) for a set of discrete groups (arranged on the x axis).\n\n\nWhat is your best estimate of the number of Blaster type slimes?\n\nA. 11\nB. 1\nC. 0 to 300\nD. 46\n\n\n\n\nClick to see the answer\n\nAnswer: A. 11\nExplanation: The number of slimes for each type is represented by the height of each bar. Try hovering over the Blaster type bar to see its corresponding value for the y axis.\n\n\nWhat type of slime is the least frequent in the population?\n\nA. Blaster\nB. Basic\nC. Acid\nD. Fire\n\n\n\n\nClick to see the answer\n\nAnswer: D. Fire\nExplanation: The least frequent slime type is the represented by the bar with the lowest value. In this case, there are only XXX fire slimes, a number lower than all the other groups.\n\n\n\nNow that a few generations have passed, we can introduce the concept of fitness. In this case, the enemies are being evaluated by how close they are getting to the space sheep. We can use a scatterplot to show the player the relationship between fitness and the number of offspring produced by each enemy.\n\n\nCode\n# Create a scatterplot using plotly\nfig = px.scatter(df_wave_4, \n                 x='Sheep Distance Fitness', \n                 y='Offspring Count',\n                 title='Scatterplot of Fitness Trait vs number of Offspring (Wave Number = 4)')\n\n# Update the layout for better readability\nfig.update_layout(\n    xaxis_title='Sheep Fitness',\n    yaxis_title='Offspring'\n)\n\n# Save the plot as an HTML file\nfig.write_html('fit_babies_scatterplot.html')\n\n# Display the plot\nfig.show()\n\n\n                                                \n\n\n\nWhat type of relationship appears to exist between Fitness trait and number of Offspring?\n\nA. Strong positive correlation\nB. Strong negative correlation\nC. Weak positive correlation\nD. No clear correlation\n\n\nClick to see the answer\n\nAnswer: A. Strong positive correlation\n\n\nExplanation: The scatterplot shows a strong positive correlation between Fitness and offspring.\n\n\nWhat is the approximate range of values for the number of offspring?\n\nA. 0 to 6\nB. 0 to 12\nC. -6 to 6\nD. -12 to 12\n\n\nClick to see the answer\n\nAnswer: B. 0 to 12\n\n\nExplanation: The y-axis of the scatterplot represents the number of offspring. The lowest point value is at zero and the highest is 12.\n\n\nOn this graph, what does each individual point (circle) represent?\n\nA. The maximum value of [Trait 1] and [Trait 2] from all previous Generations of slimes.\nB. The average values of the Traits for each slime from Generation X.\nC. The exact values of [Trait 1] and [Trait 2] for each slime from Generation X.\nD. The probability that each Slime will reproduce this generation.\n\n\nClick to see the answer\n\nAnswer: C. The exact values of [Trait 1] and [Trait 2] for each slime from Generation X.\n\n\nExplanation: This is a scatter plot of trait values from the previous generation. A scatterplot plots exact values for two quantitative variables (Traits) on two orthogonal axes."
  },
  {
    "objectID": "posts/Certificate/index.html",
    "href": "posts/Certificate/index.html",
    "title": "CERTIFICATE",
    "section": "",
    "text": "Learn how to think about, organize, analyze, and visualize data. Communicate data-driven insights to technical and lay audiences."
  },
  {
    "objectID": "posts/Certificate/index.html#overview",
    "href": "posts/Certificate/index.html#overview",
    "title": "CERTIFICATE",
    "section": "OVERVIEW",
    "text": "OVERVIEW\nWe live in an increasingly data-driven world. Basic data literacy and data science skills are becoming central to virtually every industry. Yet, limited opportunities exist to gain these skills without an advanced background in math and computer science. To address this workforce development need, we propose a competitively valued on-line graduate certificate in the Professional Applications in Data Science. The certificate is designed to offer rigorous training in the foundations of data science to anyone with a bachelor’s degree. Participants will learn how to think about, organize, analyze, and visualize data, and communicate data driven insights to diverse audiences. The curriculum emphasizes the use of data sets drawn from each student’s individual discipline, aligning the certificate’s workforce development impacts with the University of Idaho’s land grant mission.\n\nValue Proposition:\nThe graduate certificate in Professional Applications in Data Science will provide unique value to UI constituencies by:\n\nAligning data science training with fields of nascent demand that are part of our land grant mission, including Agriculture, Natural Resources, and Education.\nRequiring a digital data science portfolio with which students can demonstrate their proficiencies to potential employers.\nEmphasizing training in data communication - including verbal presentation and data visualization - two components of data science that are underrepresented in competing certificates.\nFilling a growing workforce development gap by offering a unique data science certificate that is appropriate for professionals with a bachelor’s degree who do not have a rigorous background in mathematics, statistics, or computer science.\n\n\n\nIntended Audience:\nThis certificate leverages the University of Idaho’s interdisciplinary culture to provide integrative training in the foundations of data science. It is intended for:\n\nWorking professionals with a bachelor’s degree whose career increasingly involves the generation, management, analysis, and visualization of large data sets. The certificate is appropriate for professionals in STEM fields, Health Care, Business, Government, Education, Journalism, Athletics, Natural Resources, and Agriculture.\nGraduate students in programs outside of the core technical disciplines of data science (statistics, math, engineering, or computer science). The certificate will complement disciplinary research methods courses with training in data management, visualization, and communication.\nUndergraduates at the UI who wish to incorporate data science training into their degree and graduate with a Bachelor’s degree and a graduate certificate.\n\n\n\nStudent Learning Outcomes:\nUpon completion of the certificate, students will be able to:\n\nUse open-source software to reproducibly manage, analyze, and visualize large, complex, and noisy data sets.\nPractice high quality and ethical data stewardship.\nUnderstand and execute data exploration.\nEffectively communicate data driven insights to experts and non-experts.\nDemonstrate their skills with an online portfolio of analyses and visualizations relevant to their field of specialization."
  },
  {
    "objectID": "posts/Certificate/index.html#curriculum",
    "href": "posts/Certificate/index.html#curriculum",
    "title": "CERTIFICATE",
    "section": "CURRICULUM",
    "text": "CURRICULUM\n\nPrerequisites:\nA Bachelor’s degree OR the student has senior standing and is enrolled in a bachelor’s degree program at the University of Idaho.\n\n\nCertificate Requirements (12 Credits Total)\n\n\n\n\n\n\n\n\n\n\n\n\nCourse\nName\nCredits\nPrerequisites\nSchedule\n\n\n\n\nINTR 509\nIntroduction to Applied Data Science\n3\nBS degree or permission\nSpring and asynchronous online\n\n\nBCB 551\nCommunicating with Data\n2\nINTR 509 or BS degree or permission\nFall and asynchronous online\n\n\nBCB 520\nData Visualization\n3\nSTAT 251 or INTR 509 or permission\nSpring and asynchronous online\n\n\nBCB 522\nData Science Portfolio\n1\nINTR 509 and BCB 520 (Data Viz)\nAsynchronous online\n\n\nElective\nVaries\n3\nVaries\nVaries\n\n\n\n\n\nnote: Courses designated with “BCB 5XX” are new courses that will be offered in the 2023-24 academic year\n\n\nCourse Descriptions\n\nINTR 509 Introduction to Applied Data Science (3 credits)\nIn person (spring) and asynchronous online.\nStudents are provided a foundation for “thinking with data” through the introduction of computational, statistical, and data literacy skills. This includes the selection, collection, cleaning, management, descriptive analysis, and exploratory analysis of a dataset unique to their professional interests using modern computing languages. This course is taught by Dr. Michael Overton.\n\n\nBCB 521 Communicating with Data (2 credits)\nIn person (fall) and asynchronous online.\nStudents are taught writing and presentation skills to improve their communication of data-driven insights to specialist and lay audiences. The course emphasizes reproducible research practices, including literate programming (R Markdown) and version control (GitHub). Course content includes the conceptual foundations of communicating with data along with written and verbal communication assignments using data sets individualized to each student’s interest.\nText: Nolan and Stoudt. 2021. Communicating with data: The art of writing for data science. Oxford University Press.\nPrerequisites: INTR 509 OR A BS degree OR permission.\n\n\nBCB 520 Data Visualization (3 credits)\nIn person (spring) and asynchronous online\nThis course covers the conceptual foundations of data visualization and design. Students will learn how visualization design choices related to marks and channels, color, and spatial arrangement interact with the human perceptual system. The course considers tabular, network, and spatial data, and students will implement visualizations in R.\nText: Munzner. 2014. Visualization Analysis & Design. CRC Press.\nPrerequisites: INTR 509 OR A BS degree OR Stat 251 OR Permission.\n\n\nBCB 522 Online Portfolio (1 credit)\nAsynchronous online\nThis course provides feedback, review, and approval of the student’s online data science portfolio. This portfolio is intended to represent the body of work accumulated by the student over the course of the certificate. It should contain examples of novel data products (such as FAIR data sets), analyses, and visualizations. All elements of the portfolio will be hosted online (likely in a GitHub repository or professional website), be open source, and demonstrate best practices of literate programming and reproducible research.\n\n\nElectives:\nThe certificate allows each student to customize their training by choosing a 3-credit graduate elective.\nFor students seeking foundational training who have not already taken Stat 431 or its equivalent, we recommend Stat 431 or a 3-credit graduate level disciplinary research methods course.\nFor students seeking to add the certificate to an existing degree at UI, or students who already have some advanced technical training, additional electives are possible. Note that many of these optional electives have substantial disciplinary pre-requisites. Not all electives are available in an online format.\n\n\nChoose one of the following:\n\n\n\n\n\nCourse\nName\nCredits\nPrerequisites\n\n\n\n\nAVS 531\nPractical Methods in Analyzing Animal Science Experiments\n3\n400-level statistics course\n\n\nBE 521\nImage Processing and Computer Vision\n3\n(BE 242 and MATH 275) or permission\n\n\nBE 541\nInstrumentation and Measurements\n3\nENGR 240; Coreqs: STAT 301\n\n\nBIOL 526\nSystems Biology\n3\n(BIOL 115, BIOL 115L and MATH 170) or permission of instructor\n\n\nBIOL 545\nPhylogenetics\n3\nPLSC 205 or BIOL 213 and BIOL 310\n\n\nBIOL 549\nComputer Skills for Biologists\n3\nBIOL 310 and STAT 251 or STAT 301; or Permission\n\n\nBIOL 563\nMathematical Genetics\n3\nMATH 160 or MATH 170 and STAT 251 or STAT 301\n\n\nCE 526\nAquatic Habitat Modeling\n3\nA minimum grade of ‘C’ or better is required for all pre/corequisites; Prereqs: CE 322 and CE 325 or BE 355; or Permission\n\n\nCE 579\nSimulation of Transportation Systems\n3\nPermission\n\n\nCS 511\nParallel Programming\n3\nCS 395\n\n\nCS 574\nDeep Learning\n3\n(CS 121 or MATH 330) and STAT 301\n\n\nCS 570\nArtificial Intelligence\n3\nCS 210\n\n\nCS 572\nEvolutionary Computation\n3\nCS 211\n\n\nCS 575\nMachine Learning\n3\nCS 210\n\n\nCS 577\nPython for Machine Learning\n3\n(CS 121 or MATH 330) and STAT 301\n\n\nCS 578\nNeural Network Design\n3\nPermission\n\n\nCS 579\nData Science\n3\nMATH 330 or Permission\n\n\nCS 589\nSemantic Web and Open Data\n3\nCS 360 or CS 479 or CS 579\n\n\nCTE 519\nDatabase Applications and Information Management\n3\nNA\n\n\nCYB 520\nDigital Forensics\n3\nCYB 310\n\n\nED 571\nIntroduction to Quantitative Research\n3\nGraduate standing\n\n\nED 584\nUnivariate Quantitative Research in Education\n3\nED 571\n\n\nED 587\nMultivariate Quantitative Analysis in Education\n3\nED 584 or Permission\n\n\nED 589\nTheoretical Applications and Designs of Qualitative Research\n3\nED 574 or Permission\n\n\nED 590\nData Analysis and Interpretation of Qualitative Research\n3\nED 574 and ED 589\n\n\nED 591\nIndigenous and Decolonizing Research Methods\n3\nNA\n\n\nED 592\nDecolonizing, Indigenous, and Action-Based Research Methods\n3\nNA\n\n\nED 595\nSurvey Design for Social Science Research\n3\nRecommended Preparation: Foundations of Research course at graduate level.\n\n\nEDAD 570\nMethods of Educational Research\n3\nNA\n\n\nENT 504\nApplied Bioinformatics\n3\nPermission\n\n\nENVS 511\nData Wizardry in Environmental Sciences\n3\nSTAT 251\n\n\nENVS 551\nResearch Methods in the Environmental Social Sciences\n3\nOne course or experience in basic statistics or Instructor Permission\n\n\nFOR 514\nForest Biometrics\n3\nSTAT 431 or equivalent\n\n\nFOR 535\nRemote Sensing of Fire\n3\nFOR 375 or permission\n\n\nGEOG 507\nSpatial Statistics and Modeling\n3\nSTAT 431 or permission\n\n\nGEOG 583\nRemote Sensing/GIS Integration\n3\nCoreqs: GEOG 385 or equivalent.\n\n\nMath 538\nStochastic Models\n3\nMATH 451 or Permission\n\n\nMIS 555\nData Management for Big Data\n3\nNA\n\n\nNRS 578\nLidar and optical remote sensing analysis using open-source software\n3\nSTAT251 & WLF370 or STAT427 and NRS/FOR 472 or equivalent/instructor permission\n\n\nPOLS 558\nResearch Methods for Local Government and Community Administration\n3\nSTAT 251\n\n\nREM 507\nLandscape and Habitat Dynamics\n3\nPermission; Recommended Preparation: courses in ecology, statistics, and GIS.\n\n\nStat 431\nStatistical Analysis\n3\nSTAT 251 or STAT 301\n\n\nSTAT 514\nNonparametric Statistics\n3\nSTAT 431\n\n\nSTAT 516\nApplied Regression Modeling\n3\nSTAT 431\n\n\nStat 517\nStatistical Learning and Predictive Modeling\n3\nSTAT 431\n\n\nStat 519\nMultivariate Analysis\n3\nSTAT 431 or equivalent.\n\n\nSTAT 535\nIntroduction to Bayesian Statistics\n3\nSTAT 431\n\n\nSTAT 555\nStatistical Ecology\n3\nMATH 451 or Permission\n\n\nStat 565\nComputer Intensive Methods\n3\n STAT 451, STAT 452, MATH 330, and computer programming experience or Permission\n\n\nWLF 552\nEcological Modeling\n3\nMATH 175 and FOR 221 or Permission.\n\n\nWLF 555\nStatistical Ecology\n3\nMATH 451 or permission\n\n\nWR 552\nWater Economics and Policy\n3\nAGEC 301 or AGEC 302, or ECON 351 or ECON 352, or by permission"
  },
  {
    "objectID": "posts/Certificate/index.html#general-university-requirements",
    "href": "posts/Certificate/index.html#general-university-requirements",
    "title": "CERTIFICATE",
    "section": "GENERAL UNIVERSITY REQUIREMENTS",
    "text": "GENERAL UNIVERSITY REQUIREMENTS\nIn addition to the requirements specified in this document, the certificate would be subject to all UI Policies regarding Graduate Certificates."
  },
  {
    "objectID": "posts/L3-FigureCaptions/Captions.html#writing-about-data",
    "href": "posts/L3-FigureCaptions/Captions.html#writing-about-data",
    "title": "LECTURE 3 - CAPTIONS",
    "section": "Writing About Data",
    "text": "Writing About Data\nA figure is worth 1000 words…. or some crap… I don’t know…"
  },
  {
    "objectID": "posts/L3-FigureCaptions/Captions.html#remember-our-theme",
    "href": "posts/L3-FigureCaptions/Captions.html#remember-our-theme",
    "title": "LECTURE 3 - CAPTIONS",
    "section": "REMEMBER OUR THEME!",
    "text": "REMEMBER OUR THEME!\nWho is the Audience? What is the goal?\nAny general advice can be invalidated by your specific requirements. For example, the Associate Editor of the Journal Science won’t care what you learned in this class. They have guidelines and you must follow them."
  },
  {
    "objectID": "posts/L3-FigureCaptions/Captions.html#self-contained",
    "href": "posts/L3-FigureCaptions/Captions.html#self-contained",
    "title": "LECTURE 3 - CAPTIONS",
    "section": "SELF CONTAINED",
    "text": "SELF CONTAINED\nThe caption and the figure should create a stand alone entity that can be understood without reference to the main text of the document. Components may include:\n\nDeclarative Title.\nMethods.\nStatistical Information."
  },
  {
    "objectID": "posts/L3-FigureCaptions/Captions.html#declarative-title",
    "href": "posts/L3-FigureCaptions/Captions.html#declarative-title",
    "title": "LECTURE 3 - CAPTIONS",
    "section": "DECLARATIVE TITLE",
    "text": "DECLARATIVE TITLE\n… or not?\nA Declarative Title summarizes your result or main finding. This may or may not be appropriate. Is the title clarifying the communication or biasing the reader?"
  },
  {
    "objectID": "posts/L3-FigureCaptions/Captions.html#methods-and-statistics",
    "href": "posts/L3-FigureCaptions/Captions.html#methods-and-statistics",
    "title": "LECTURE 3 - CAPTIONS",
    "section": "METHODS AND STATISTICS",
    "text": "METHODS AND STATISTICS"
  },
  {
    "objectID": "posts/L3-FigureCaptions/Captions.html#caption-vs-legend",
    "href": "posts/L3-FigureCaptions/Captions.html#caption-vs-legend",
    "title": "LECTURE 3 - CAPTIONS",
    "section": "CAPTION vs LEGEND",
    "text": "CAPTION vs LEGEND"
  },
  {
    "objectID": "posts/L3-FigureCaptions/Captions.html#scope",
    "href": "posts/L3-FigureCaptions/Captions.html#scope",
    "title": "LECTURE 3 - CAPTIONS",
    "section": "SCOPE",
    "text": "SCOPE\n1 Figure for 1 Question."
  },
  {
    "objectID": "posts/L3-FigureCaptions/Captions.html#now-you-try",
    "href": "posts/L3-FigureCaptions/Captions.html#now-you-try",
    "title": "LECTURE 3 - CAPTIONS",
    "section": "NOW YOU TRY!",
    "text": "NOW YOU TRY!\nGrab one of your figures from your previous assignments. Write a comprehensive figure caption.\n\n\n\nHOME"
  },
  {
    "objectID": "posts/L2-Goals/goals.html#goals-in-data-driven-communication",
    "href": "posts/L2-Goals/goals.html#goals-in-data-driven-communication",
    "title": "LECTURE 2 - GOALS",
    "section": "Goals in Data-Driven Communication",
    "text": "Goals in Data-Driven Communication"
  },
  {
    "objectID": "posts/L2-Goals/goals.html#overarching-goals-long-term-objectives",
    "href": "posts/L2-Goals/goals.html#overarching-goals-long-term-objectives",
    "title": "LECTURE 2 - GOALS",
    "section": "1. Overarching Goals (Long-term Objectives)",
    "text": "1. Overarching Goals (Long-term Objectives)\n\nCareer Advancement: e.g., Landing a job, securing a promotion\nBusiness Development: e.g., Selling a product, gaining investors\nPolicy Change: e.g., Influencing legislation, changing organizational policies\nRelationship Building: e.g., Establishing partnerships, improving client relations\nReputation Enhancement: e.g., Establishing thought leadership, building credibility"
  },
  {
    "objectID": "posts/L2-Goals/goals.html#communication-specific-goals-immediate-objectives",
    "href": "posts/L2-Goals/goals.html#communication-specific-goals-immediate-objectives",
    "title": "LECTURE 2 - GOALS",
    "section": "2. Communication-Specific Goals (Immediate Objectives)",
    "text": "2. Communication-Specific Goals (Immediate Objectives)\n\nInform: Present data to increase understanding or awareness\nEducate: Teach concepts or skills related to the data\nPersuade: Use data to convince the audience of a particular viewpoint\nMotivate: Inspire action based on the data presented\nDecision Support: Provide data to aid in decision-making processes\nProblem-Solving: Present data to help identify solutions to issues\nCompliance: Fulfill regulatory or organizational reporting requirements"
  },
  {
    "objectID": "posts/L2-Goals/goals.html#audience-centric-goals",
    "href": "posts/L2-Goals/goals.html#audience-centric-goals",
    "title": "LECTURE 2 - GOALS",
    "section": "3. Audience-Centric Goals",
    "text": "3. Audience-Centric Goals\n\nAddress Needs: Satisfy the audience’s information requirements\nAnswer Questions: Provide data-driven responses to specific queries\nChallenge Perceptions: Use data to question existing beliefs or assumptions\nFacilitate Discussion: Present data as a starting point for dialogue\nEmpower: Equip the audience with data for their own use or analysis"
  },
  {
    "objectID": "posts/L2-Goals/goals.html#data-specific-goals",
    "href": "posts/L2-Goals/goals.html#data-specific-goals",
    "title": "LECTURE 2 - GOALS",
    "section": "4. Data-Specific Goals",
    "text": "4. Data-Specific Goals\n\nClarity: Ensure complex data is understood accurately\nEngagement: Make data interesting and relevant to the audience\nMemorability: Present data in a way that’s easy to remember and recall\nAction-Oriented: Transform data insights into actionable steps\nTransparency: Provide clear information about data sources and methods"
  },
  {
    "objectID": "posts/L2-Goals/goals.html#presentation-goals",
    "href": "posts/L2-Goals/goals.html#presentation-goals",
    "title": "LECTURE 2 - GOALS",
    "section": "5. Presentation Goals",
    "text": "5. Presentation Goals\n\nTime Management: Convey key information within the allotted time\nVisual Appeal: Create aesthetically pleasing data visualizations\nInteractivity: Engage the audience through participatory data exploration\nAccessibility: Ensure the data presentation is inclusive and understandable to all audience members\n\n\n\n\nHOME"
  },
  {
    "objectID": "posts/L1-Intro/index.html#who-am-i",
    "href": "posts/L1-Intro/index.html#who-am-i",
    "title": "LECTURE 1 - INTRO",
    "section": "WHO AM I?",
    "text": "WHO AM I?\nBarrie Robison\nDepartment of Biological Sciences\nInstitute for Interdisicplinary Data Sciences\nPolymorphic Games\nUniversity of Idaho"
  },
  {
    "objectID": "posts/L1-Intro/index.html#who-are-you",
    "href": "posts/L1-Intro/index.html#who-are-you",
    "title": "LECTURE 1 - INTRO",
    "section": "WHO ARE YOU?",
    "text": "WHO ARE YOU?\n“…The course is designed to be”discipline agnostic” - each student is encouraged to use their own data, or public data sets that they deem important / interesting. …”\nBriefly:\n\nYour name\nYour discipline\nYour degree progress\nYour technical proficiency"
  },
  {
    "objectID": "posts/L1-Intro/index.html#yva",
    "href": "posts/L1-Intro/index.html#yva",
    "title": "LECTURE 1 - INTRO",
    "section": "YVA",
    "text": "YVA"
  },
  {
    "objectID": "posts/L1-Intro/index.html#sean",
    "href": "posts/L1-Intro/index.html#sean",
    "title": "LECTURE 1 - INTRO",
    "section": "SEAN",
    "text": "SEAN"
  },
  {
    "objectID": "posts/L1-Intro/index.html#morjina",
    "href": "posts/L1-Intro/index.html#morjina",
    "title": "LECTURE 1 - INTRO",
    "section": "MORJINA",
    "text": "MORJINA"
  },
  {
    "objectID": "posts/L1-Intro/index.html#zoe",
    "href": "posts/L1-Intro/index.html#zoe",
    "title": "LECTURE 1 - INTRO",
    "section": "ZOE",
    "text": "ZOE"
  },
  {
    "objectID": "posts/L1-Intro/index.html#course-summary",
    "href": "posts/L1-Intro/index.html#course-summary",
    "title": "LECTURE 1 - INTRO",
    "section": "COURSE SUMMARY",
    "text": "COURSE SUMMARY\nStudents completing this course will be able to:\n\n\nIdentify, understand, and describe the critical characteristics, needs, and expectations of the various audiences with whom they will communicate.\nDevelop and apply effective writing and presentation skills to communicate data-driven insights clearly and impactfully to both specialist and general audiences.\nImplement reproducible research practices using literate programming (Quarto/Markdown) and version control (GitHub) to enhance the transparency and reproducibility of their work.\nCreate compelling narratives around data that are tailored to specific disciplines while remaining accessible to interdisciplinary audiences.\nCritically evaluate and apply appropriate data visualization techniques to support written and verbal communications, enhancing the accessibility of complex data analysis results."
  },
  {
    "objectID": "posts/L1-Intro/index.html#central-dogma",
    "href": "posts/L1-Intro/index.html#central-dogma",
    "title": "LECTURE 1 - INTRO",
    "section": "CENTRAL DOGMA",
    "text": "CENTRAL DOGMA\nWho is the AUDIENCE and what is the GOAL?"
  },
  {
    "objectID": "posts/L1-Intro/index.html#the-audience",
    "href": "posts/L1-Intro/index.html#the-audience",
    "title": "LECTURE 1 - INTRO",
    "section": "THE AUDIENCE",
    "text": "THE AUDIENCE\nWhat kind of audiences?\nCan they be categorized or grouped?"
  },
  {
    "objectID": "posts/L1-Intro/index.html#the-goal",
    "href": "posts/L1-Intro/index.html#the-goal",
    "title": "LECTURE 1 - INTRO",
    "section": "THE GOAL",
    "text": "THE GOAL\nWhat kind of goals?\nCan they be categorized or grouped?"
  },
  {
    "objectID": "posts/L1-Intro/index.html#the-strategy",
    "href": "posts/L1-Intro/index.html#the-strategy",
    "title": "LECTURE 1 - INTRO",
    "section": "THE STRATEGY",
    "text": "THE STRATEGY\nHow can the goal be achieved with this audience?\nIs this concept too abstract to discuss?"
  },
  {
    "objectID": "posts/L1-Intro/index.html#the-medium",
    "href": "posts/L1-Intro/index.html#the-medium",
    "title": "LECTURE 1 - INTRO",
    "section": "THE MEDIUM",
    "text": "THE MEDIUM\nWhat are the possible communication channels with our audience?\nHow do these channels align with our modes of communication (showing, speaking, writing)?"
  },
  {
    "objectID": "posts/L1-Intro/index.html#technical-components",
    "href": "posts/L1-Intro/index.html#technical-components",
    "title": "LECTURE 1 - INTRO",
    "section": "TECHNICAL COMPONENTS",
    "text": "TECHNICAL COMPONENTS\nLiterate Programming\nVersion Control\nArtificial Intelligence"
  },
  {
    "objectID": "posts/L1-Intro/index.html#summary",
    "href": "posts/L1-Intro/index.html#summary",
    "title": "LECTURE 1 - INTRO",
    "section": "SUMMARY",
    "text": "SUMMARY\nWho is the AUDIENCE? What is the GOAL?\n\nAUDIENCEGOALS\n\n\n\nReceptivity: Are they hostile to your message, or predisposed to it?\nInfluence: Do they have the power to help you achieve your goal?\nEngagement: Are you competing with other factors for their attention?\nExpertise: How much prior knowledge do they have related to your content?\nNeeds: What type of affordances must you provide? Consider the required access to technology for your communication.\nExpectations: Are there disciplinary or cultural norms or expectations (e.g. formality, format, content)?\nDiversity: How big is the audience, and how much variation in the above characteristics may exist among individuals?\nGoals: Your audience has goals too. How do their goals align with yours?\n\n\n\n\nOverarching goals (Long-term Objectives): Get the job, sell the product, get elected, confirm or refute your hypothesis.\nCommunication-Specific goals (Immediate Objectives): Inform the voters, educate the students, persuade the legislator, motivate the staff, solve a problem.\nMultiple Goals: Most communications will have multiple goals across these categories. The challenge is often in balancing these goals effectively.\nAlignment: Ensure that your communication-specific goals align with your overarching goals and are appropriate for your audience characteristics.\nMeasurability: Where possible, try to make goals specific and measurable. This can help in evaluating the success of your communication.\nFlexibility: Be prepared to adjust your goals based on feedback or changing circumstances.\n\n\n\n\n\n\n\nHOME"
  },
  {
    "objectID": "posts/A4-CodeCommunication/index.html",
    "href": "posts/A4-CodeCommunication/index.html",
    "title": "ASSIGNMENT 4 - Communicating with Code.",
    "section": "",
    "text": "While we generally tend to focus on the more common channels of communication in this class (Speaking, Writing, Showing), we should acknowledge that communicating with code is becoming very common. In this assignment, we’ll take your most recent data figure(s) and explore how literate programming and version control can be valuable tools for communicating your data science activities. Github is fun!!!"
  },
  {
    "objectID": "posts/A4-CodeCommunication/index.html#summary",
    "href": "posts/A4-CodeCommunication/index.html#summary",
    "title": "ASSIGNMENT 4 - Communicating with Code.",
    "section": "",
    "text": "While we generally tend to focus on the more common channels of communication in this class (Speaking, Writing, Showing), we should acknowledge that communicating with code is becoming very common. In this assignment, we’ll take your most recent data figure(s) and explore how literate programming and version control can be valuable tools for communicating your data science activities. Github is fun!!!"
  },
  {
    "objectID": "posts/A4-CodeCommunication/index.html#assignment",
    "href": "posts/A4-CodeCommunication/index.html#assignment",
    "title": "ASSIGNMENT 4 - Communicating with Code.",
    "section": "ASSIGNMENT",
    "text": "ASSIGNMENT\nUse your most recent data figure(s) and create a new blog post in your portfolio.\n\nAnnotate your post using Markdown syntax. Use headers, lists, and other markdown tools to create a document that helps the audience understand the logic of your analysis and any decisions you made.\nWithin each code chunk, use comments to describe what each major piece of your code is intended to do."
  },
  {
    "objectID": "posts/A4-CodeCommunication/index.html#evaluation",
    "href": "posts/A4-CodeCommunication/index.html#evaluation",
    "title": "ASSIGNMENT 4 - Communicating with Code.",
    "section": "EVALUATION",
    "text": "EVALUATION\nIn class, we will randomly trade code with a partner (including me). Our goal is to download, run, and explain the code from your partner. Fun!"
  },
  {
    "objectID": "posts/A4-CodeCommunication/index.html#resources",
    "href": "posts/A4-CodeCommunication/index.html#resources",
    "title": "ASSIGNMENT 4 - Communicating with Code.",
    "section": "RESOURCES",
    "text": "RESOURCES\nQuarto Markdown Basics\nFor extra flair, try Code Annotations!"
  },
  {
    "objectID": "posts/index.html",
    "href": "posts/index.html",
    "title": "Tutorial 2 - Communicating with Code",
    "section": "",
    "text": "Test!"
  },
  {
    "objectID": "posts/A2-VersionControl/index.html",
    "href": "posts/A2-VersionControl/index.html",
    "title": "ASSIGNMENT 2",
    "section": "",
    "text": "The basic idea of this assignment is to set up a GitHub repository that will serve as an experimental portfolio, and then create a practice communication element inside the portfolio. Its gonna be fun! Or at least educational…"
  },
  {
    "objectID": "posts/A2-VersionControl/index.html#summary",
    "href": "posts/A2-VersionControl/index.html#summary",
    "title": "ASSIGNMENT 2",
    "section": "",
    "text": "The basic idea of this assignment is to set up a GitHub repository that will serve as an experimental portfolio, and then create a practice communication element inside the portfolio. Its gonna be fun! Or at least educational…"
  },
  {
    "objectID": "posts/A2-VersionControl/index.html#assignment",
    "href": "posts/A2-VersionControl/index.html#assignment",
    "title": "ASSIGNMENT 2",
    "section": "ASSIGNMENT",
    "text": "ASSIGNMENT\nThis assignment has two parts. The first part is technical. We’ll set up a Quarto Blog project as a new repository in your GitHub account. Then you’ll be a Blogger! Prestigious! The second part should be more fun. We are going to create your first Blog post using a practice / dummy / simple quarto document. Ideally this would be your .qmd file from Assigment 1."
  },
  {
    "objectID": "posts/A2-VersionControl/index.html#part-1-technical-sorcery",
    "href": "posts/A2-VersionControl/index.html#part-1-technical-sorcery",
    "title": "ASSIGNMENT 2",
    "section": "PART 1 TECHNICAL SORCERY",
    "text": "PART 1 TECHNICAL SORCERY\n\n1A - Create your BLOG project.\nHopefully by now you have created / dusted off / logged in to your GitHub account. Go ahead and log in to your account on the web and leave it open in a tab in your browser. There is a really great video about the next few steps (also linked below in RESORUCES) from Posit, but I’m giving you the condensed version here.\n\nFire up RStudio.\nGo to File-&gt;New Project and then select NEW DIRECTORY.\nNow select QUARTO BLOG.\nYou are going to create the project in a new working directory. It is best practice to put this in a sensible directory structure on your local hard drive where your other GitHub repositories also live. Here is what mine looks like:\n\n\nNote: I currently have my GitHub directory in my Documents folder, which appears to sync with some kind of Apple Cloud thingy. I think this is causing some issues that I haven’t fully dealt with. I don’t recommend putting your local directory on any kind of shared or networked drive.\n\nI suggest making the directory name something informative, like BCB521Portfolio, but hey… If you want to call your repository HasturBoxerShorts I won’t stop you.\nMost of you will select Knitr as your Engine, but if you were a Python coder you might select Jupyter.\nCheck Create a git repository. At some point, you might be asked about making the repository private. Uncheck that box and make it public. Otherwise the website functionality of GitHub pages won’t work. The other boxes are optional and we can talk more about them later.\nClick CREATE PROJECT.\n\nNow you’ve got a BLOG template all set up! Ha Ha! Onward to Internet Fame!\n\n\n1B - Make the BLOG about you.\nWe won’t spend a ton of time here, because this will be an ongoing process. You’ll go and watch all those cool videos and tutorials this weekend to figure this out. But lets do a couple things.\n\nMaybe you should modify the about.qmd file so that your name is in there somewhere.\nMaybe you should modify the index.qmd file with a better title in the YAML header.\nMaybe you should navigate to the posts folder, open the Welcome to my blog folder, open index.qmd from that directory, and add a sentence or two."
  },
  {
    "objectID": "posts/A2-VersionControl/index.html#part-2-internet-fame",
    "href": "posts/A2-VersionControl/index.html#part-2-internet-fame",
    "title": "ASSIGNMENT 2",
    "section": "PART 2 INTERNET FAME",
    "text": "PART 2 INTERNET FAME\n\n2A - Make Assignment 1 a BLOG post.\n\nNavigate to the posts folder, open the post with code folder, and open index.qmd.\nReplace ALL of the content of index.qmd with the most recent version of your .qmd file from ASSIGNMENT 1. Keep the file name index.qmd or rename it to something else. Save that file!\nMove any data files pertaining to Assignment 1 to the post with code folder.\nRender the index.qmd file (or whatever you renamed it) from this folder. Hopefully it worked!\n\n\n\n2B - Render the BLOG as a website.\n\nIMPORTANT Open your _quarto.yml file and add output-dir: docs under project:\n\n\nThe indentations matter here.\n\nSave all the files you’ve modified.\nGo to the BUILD tab in the (probably) top right section of RStudio.\nClick RENDER WEBSITE.\nClick through your new Blog and see how it works!\n\n\n\n2C - Push to GitHub.\nThere are quite a few ways to do this part. I’m going to use GitHub Desktop, but those videos will show you other ways.\n\nGo to GitHub Desktop.\nYou may have to add your repository to GitHub Desktop. On my Mac I use File -&gt; Add Local Repository and then point to the local directory.\nType some text in the summary box.\nClick COMMIT TO MASTER.\nClick PUSH ORIGIN.\nGo to your GitHub in your browser. You should see your new repository! Yay!\n\n\n\n2D - Make it a website with GitHub pages.\n\nIn your browser, click on your repository.\nGo to SETTINGS.\nSelect PAGES.\nSet the SOURCE option to Deploy from a branch.\nSet the BRANCH to master and the directory to docs\nDeploy that stuff and wait. Then visit your site!"
  },
  {
    "objectID": "posts/A2-VersionControl/index.html#resources",
    "href": "posts/A2-VersionControl/index.html#resources",
    "title": "ASSIGNMENT 2",
    "section": "RESOURCES",
    "text": "RESOURCES\nA YouTube Video from Posit on Building your Data Science Portfolio\nQuarto’s BLOG Documentation\nA YouTube Video from Posit on Building a BLOG with Quarto"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "BCB 521:: Communicating with Data",
    "section": "",
    "text": "Students are taught writing and presentation skills to improve their communication of data-driven insights to specialist and lay audiences. The course emphasizes reproducible research practices, including literate programming (Quarto / Markdown) and version control (GitHub). Course content includes the conceptual foundations of communicating with data along with written and verbal assignments using data sets individualized to each student’s interest. The course is designed to be “discipline agnostic” - each student is encouraged to use their own data, or public data sets that they deem important / interesting.\n\n\nSYLLABUS\nBarrie’s GitHub\nBCB521 Repository\n\n\n\n\n\n\nThe Functional Art\nGGSIDE! A companion to ggplot for making side plots! COOL!\nAwesome Quarto: A potentially interesting repository of Quarto documents, talks, tools, examples, etc.\nThe MockUp Blog - TABLES! This blog post explores the R packages gt and gtextras which will help us up our table game!\nRiffomonas Project: Pat Schloss is a Professor at the University of Michigan. The Riffomonas Project is his Youtube channel, which has HUNDREDS of easy to follow and amazingly useful instructional videos on R, ggplot, version control, and literate programming.\nDr. Tamara Munzner’s Website: It isn’t fancy, but Dr. Munzner’s website has tons of resources from her textbook and the many data visualization courses she has offered. This includes recorded lectures that align directly with the chapters of the text, much like what we are using.\nCheat Sheets: So many visual guides for many R packages, including the tidyverse, ggplot, dplyr, etc.\nLearning Vis Tools: Teaching Data Visualization Tutorials An interesting paper for discussion as we forge the structure for this class."
  },
  {
    "objectID": "index.html#quick-links",
    "href": "index.html#quick-links",
    "title": "BCB 521:: Communicating with Data",
    "section": "",
    "text": "SYLLABUS\nBarrie’s GitHub\nBCB521 Repository"
  },
  {
    "objectID": "index.html#learning-resources",
    "href": "index.html#learning-resources",
    "title": "BCB 521:: Communicating with Data",
    "section": "",
    "text": "The Functional Art\nGGSIDE! A companion to ggplot for making side plots! COOL!\nAwesome Quarto: A potentially interesting repository of Quarto documents, talks, tools, examples, etc.\nThe MockUp Blog - TABLES! This blog post explores the R packages gt and gtextras which will help us up our table game!\nRiffomonas Project: Pat Schloss is a Professor at the University of Michigan. The Riffomonas Project is his Youtube channel, which has HUNDREDS of easy to follow and amazingly useful instructional videos on R, ggplot, version control, and literate programming.\nDr. Tamara Munzner’s Website: It isn’t fancy, but Dr. Munzner’s website has tons of resources from her textbook and the many data visualization courses she has offered. This includes recorded lectures that align directly with the chapters of the text, much like what we are using.\nCheat Sheets: So many visual guides for many R packages, including the tidyverse, ggplot, dplyr, etc.\nLearning Vis Tools: Teaching Data Visualization Tutorials An interesting paper for discussion as we forge the structure for this class."
  }
]