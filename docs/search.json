[
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "SYLLABUS 2024",
    "section": "",
    "text": "Barrie D. Robison\nFall 2024\n\n\nThis class will help students establish a core understanding of data visualization. We will consider how data type (including tabular, network, and spatial data) interacts with visualization task to guide design choices. Diverse types of visual encodings and how they relate to human perception will be presented, along with practical exercises using the R programming language. Upon completion of the course, students will understand WHY particular visualization approaches are effective for a given data set and HOW to implement those visualizations using R. The course is designed to be “discipline agnostic” - each student is encouraged to use data sets that they deem important / interesting. The goal is to have students learn how to develop visualizations that are relevant to their own disciplinary interests.\n\n\n\nStudents completing this course will be able to:\n\nDescribe and manipulate tabular, network, and spatial data; transform these data into a form suitable for visualization.\nAnalyze data visualization design choices related to marks and channels, spatial arrangement, and components of color.\nDesign new data visualizations with appropriate use of visual channels for tabular, network, and spatial data with quantitative and categorical attributes.\nImplement their data visualization designs using existing tools in R (or other toolkits preferred by the student).\nExplain whether a visual encoding is perceptually appropriate for a specific combination of task and data.\nDemonstrate their skills with at least two novel visualizations suitable for inclusion in an online Data Science Portfolio.\n\n\n\n\nAs assigned. There is not a required textbook for this class.\n\n\n\n\n\n40% of your grade will be determined by homework exercises related to each course unit.\n20% of your grade will be determined by a mid term project (which would be a great item to include in your Data Science Portfolio).\n20% of your grade will be determined by a final project (which would be great item to include in your Data Science Portfolio).\n20% of your grade will be determined by participation in class discussions and individual meetings with the instructor.\nGRADING SCALE: The grading scale is standard: A (90 -100 %), B (89 - 80 %), C (79 - 70 %), D (69-60 %), F( below 60 %).\n\n\n\nMissing a scheduled class session is at your discretion. I will be posting all the course materials online. If a discussion or in-class exercise occurs and you miss it, you will lose those participation points. There is no way to make up those points.\n\n\n\nThe R Markdown template I used for this syllabus was created by Dr. Steven V. Miller at Stockholm University. It contained this section, which I found amusing and have therefore retained. Professor Miller’s current university asks professors to have policies written into their syllabus about what students should do if the professor is more than 15 minutes late to class. Here is my version of that policy:\nI will inform students via e-mail in advance of class if class is cancelled for the day. Events that might create such a scenario include travel obligations that emerged after the semester has begun, a family emergency that encompasses multiple days, or some other thing. I will also contact our department secretary in emergent situations, such as something happening on the way to work. Failing that, assume the worst. Alien abduction, the return of one or more Old Ones to our plane, or some kind of attack by wizards are all viable explanations for my inability to attend class. I ask that the students make sure that my story gets the proper treatment on the “Mr. Ballen” YouTube channel. I also ask that my story be narrated by Morgan Freeman and that the role of me in the made for TV movie be played by Keanu Reeves or Danny DeVito.\n\n\n\nThe bad news is that there are NO make-ups for missed exams. Don’t bother asking. The good news is that there aren’t any exams.\n\n\n\nAll students are expected to uphold the highest standards of academic honesty. This includes but is not limited to: not cheating, not using the ideas of others without giving appropriate credit (including AI tools), and not falsifying data. Any incident of academic dishonesty will be handled according to the guidelines of the University of Idaho.\n\n\n\n\n\nlibrary(readxl)\nSchedule &lt;- read_excel(\"Schedule.xlsx\")\n\nknitr::kable(Schedule, caption = '')\n\n\n\n\nDATE\nTOPIC\nACTIVITY\nRESOURCES\n\n\n\n\n2024-01-11\nIntroduction and Overview\nNA\nNA\n\n\n2024-01-16\nThe Imporance of Visualization\nLiterate Programming\nTutorial 1, Tutorial 2\n\n\n2024-01-18\nNA\nNA\nNA\n\n\n2024-01-23\nNA\nNA\nNA\n\n\n2024-01-25\nNA\nNA\nNA\n\n\n2024-01-30\nWHAT?  Abstraction of Data\nNA\nNA\n\n\n2024-02-01\nWHY?  Task Abstraction\nNA\nNA\n\n\n2024-02-06\nNA\nNA\nNA\n\n\n2024-02-08\nMARKS. Geometric elements to depict data\nNA\nNA\n\n\n2024-02-13\nNA\nNA\nNA\n\n\n2024-02-15\nNA\nNA\nNA\n\n\n2024-02-20\nNA\nNA\nNA\n\n\n2024-02-22\nCHANNELS. Controlling the appearance of marks.\nNA\nNA\n\n\n2024-02-27\nRULES OF THUMB.\nMidterm Presentations\nNA\n\n\n2024-02-29\nTABULAR DATA I\nMidterm Presentations\nNA\n\n\n2024-03-05\nTABULAR DATA II\nNA\nNA\n\n\n2024-03-07\nSPATIAL DATA I: Geographic Maps\nNA\nNA\n\n\n2024-03-12\nSpring Recess\nNA\nNA\n\n\n2024-03-14\nSpring Recess\nNA\nNA\n\n\n2024-03-19\nBarrie in Vermont\nNA\nNA\n\n\n2024-03-21\nSPATIAL DATA II:  Spatial Fields\nNA\nNA\n\n\n2024-03-26\nNETWORK DATA I\nNA\nNA\n\n\n2024-03-28\nNETWORK DATA II\nNA\nNA\n\n\n2024-04-02\nCOLOR I\nNA\nNA\n\n\n2024-04-04\nCOLOR II\nNA\nNA\n\n\n2024-04-09\nCOLOR III\nNA\nNA\n\n\n2024-04-11\nINTERACTIVITY\nNA\nNA\n\n\n2024-04-16\nMULTIPLE VIEWS\nNA\nNA\n\n\n2024-04-18\nAGGREGATION\nNA\nNA\n\n\n2024-04-23\nFILTERING\nNA\nNA\n\n\n2024-04-25\nEMBEDDING: Focus and Context\nNA\nNA\n\n\n2024-04-30\nDEAD WEEK\nFinal Presentations\nNA\n\n\n2024-05-02\nDEAD WEEK\nFinal Presentations\nNA\n\n\n2024-05-07\nFINALS WEEK\nNA\nNA"
  },
  {
    "objectID": "syllabus.html#course-description",
    "href": "syllabus.html#course-description",
    "title": "SYLLABUS 2024",
    "section": "",
    "text": "This class will help students establish a core understanding of data visualization. We will consider how data type (including tabular, network, and spatial data) interacts with visualization task to guide design choices. Diverse types of visual encodings and how they relate to human perception will be presented, along with practical exercises using the R programming language. Upon completion of the course, students will understand WHY particular visualization approaches are effective for a given data set and HOW to implement those visualizations using R. The course is designed to be “discipline agnostic” - each student is encouraged to use data sets that they deem important / interesting. The goal is to have students learn how to develop visualizations that are relevant to their own disciplinary interests."
  },
  {
    "objectID": "syllabus.html#course-objectives",
    "href": "syllabus.html#course-objectives",
    "title": "SYLLABUS 2024",
    "section": "",
    "text": "Students completing this course will be able to:\n\nDescribe and manipulate tabular, network, and spatial data; transform these data into a form suitable for visualization.\nAnalyze data visualization design choices related to marks and channels, spatial arrangement, and components of color.\nDesign new data visualizations with appropriate use of visual channels for tabular, network, and spatial data with quantitative and categorical attributes.\nImplement their data visualization designs using existing tools in R (or other toolkits preferred by the student).\nExplain whether a visual encoding is perceptually appropriate for a specific combination of task and data.\nDemonstrate their skills with at least two novel visualizations suitable for inclusion in an online Data Science Portfolio."
  },
  {
    "objectID": "syllabus.html#required-readings",
    "href": "syllabus.html#required-readings",
    "title": "SYLLABUS 2024",
    "section": "",
    "text": "As assigned. There is not a required textbook for this class."
  },
  {
    "objectID": "syllabus.html#course-policies",
    "href": "syllabus.html#course-policies",
    "title": "SYLLABUS 2024",
    "section": "",
    "text": "40% of your grade will be determined by homework exercises related to each course unit.\n20% of your grade will be determined by a mid term project (which would be a great item to include in your Data Science Portfolio).\n20% of your grade will be determined by a final project (which would be great item to include in your Data Science Portfolio).\n20% of your grade will be determined by participation in class discussions and individual meetings with the instructor.\nGRADING SCALE: The grading scale is standard: A (90 -100 %), B (89 - 80 %), C (79 - 70 %), D (69-60 %), F( below 60 %).\n\n\n\nMissing a scheduled class session is at your discretion. I will be posting all the course materials online. If a discussion or in-class exercise occurs and you miss it, you will lose those participation points. There is no way to make up those points.\n\n\n\nThe R Markdown template I used for this syllabus was created by Dr. Steven V. Miller at Stockholm University. It contained this section, which I found amusing and have therefore retained. Professor Miller’s current university asks professors to have policies written into their syllabus about what students should do if the professor is more than 15 minutes late to class. Here is my version of that policy:\nI will inform students via e-mail in advance of class if class is cancelled for the day. Events that might create such a scenario include travel obligations that emerged after the semester has begun, a family emergency that encompasses multiple days, or some other thing. I will also contact our department secretary in emergent situations, such as something happening on the way to work. Failing that, assume the worst. Alien abduction, the return of one or more Old Ones to our plane, or some kind of attack by wizards are all viable explanations for my inability to attend class. I ask that the students make sure that my story gets the proper treatment on the “Mr. Ballen” YouTube channel. I also ask that my story be narrated by Morgan Freeman and that the role of me in the made for TV movie be played by Keanu Reeves or Danny DeVito.\n\n\n\nThe bad news is that there are NO make-ups for missed exams. Don’t bother asking. The good news is that there aren’t any exams.\n\n\n\nAll students are expected to uphold the highest standards of academic honesty. This includes but is not limited to: not cheating, not using the ideas of others without giving appropriate credit (including AI tools), and not falsifying data. Any incident of academic dishonesty will be handled according to the guidelines of the University of Idaho."
  },
  {
    "objectID": "syllabus.html#class-schedule",
    "href": "syllabus.html#class-schedule",
    "title": "SYLLABUS 2024",
    "section": "",
    "text": "library(readxl)\nSchedule &lt;- read_excel(\"Schedule.xlsx\")\n\nknitr::kable(Schedule, caption = '')\n\n\n\n\nDATE\nTOPIC\nACTIVITY\nRESOURCES\n\n\n\n\n2024-01-11\nIntroduction and Overview\nNA\nNA\n\n\n2024-01-16\nThe Imporance of Visualization\nLiterate Programming\nTutorial 1, Tutorial 2\n\n\n2024-01-18\nNA\nNA\nNA\n\n\n2024-01-23\nNA\nNA\nNA\n\n\n2024-01-25\nNA\nNA\nNA\n\n\n2024-01-30\nWHAT?  Abstraction of Data\nNA\nNA\n\n\n2024-02-01\nWHY?  Task Abstraction\nNA\nNA\n\n\n2024-02-06\nNA\nNA\nNA\n\n\n2024-02-08\nMARKS. Geometric elements to depict data\nNA\nNA\n\n\n2024-02-13\nNA\nNA\nNA\n\n\n2024-02-15\nNA\nNA\nNA\n\n\n2024-02-20\nNA\nNA\nNA\n\n\n2024-02-22\nCHANNELS. Controlling the appearance of marks.\nNA\nNA\n\n\n2024-02-27\nRULES OF THUMB.\nMidterm Presentations\nNA\n\n\n2024-02-29\nTABULAR DATA I\nMidterm Presentations\nNA\n\n\n2024-03-05\nTABULAR DATA II\nNA\nNA\n\n\n2024-03-07\nSPATIAL DATA I: Geographic Maps\nNA\nNA\n\n\n2024-03-12\nSpring Recess\nNA\nNA\n\n\n2024-03-14\nSpring Recess\nNA\nNA\n\n\n2024-03-19\nBarrie in Vermont\nNA\nNA\n\n\n2024-03-21\nSPATIAL DATA II:  Spatial Fields\nNA\nNA\n\n\n2024-03-26\nNETWORK DATA I\nNA\nNA\n\n\n2024-03-28\nNETWORK DATA II\nNA\nNA\n\n\n2024-04-02\nCOLOR I\nNA\nNA\n\n\n2024-04-04\nCOLOR II\nNA\nNA\n\n\n2024-04-09\nCOLOR III\nNA\nNA\n\n\n2024-04-11\nINTERACTIVITY\nNA\nNA\n\n\n2024-04-16\nMULTIPLE VIEWS\nNA\nNA\n\n\n2024-04-18\nAGGREGATION\nNA\nNA\n\n\n2024-04-23\nFILTERING\nNA\nNA\n\n\n2024-04-25\nEMBEDDING: Focus and Context\nNA\nNA\n\n\n2024-04-30\nDEAD WEEK\nFinal Presentations\nNA\n\n\n2024-05-02\nDEAD WEEK\nFinal Presentations\nNA\n\n\n2024-05-07\nFINALS WEEK\nNA\nNA"
  },
  {
    "objectID": "posts/A2-YourData/index.html",
    "href": "posts/A2-YourData/index.html",
    "title": "ASSIGNMENT 2 - Your Data.",
    "section": "",
    "text": "A key feature of this course is that students should be using their own data whenever possible. This is critical to forging a learning experience that is customized to each student’s aspirations and the eccentricities of their chosen research domain. This assignment begins the process of helping you identify the data sets with which you want to work, and aligns with the notion of understanding the concepts of Data Semantics and Data Abstraction."
  },
  {
    "objectID": "posts/A2-YourData/index.html#summary",
    "href": "posts/A2-YourData/index.html#summary",
    "title": "ASSIGNMENT 2 - Your Data.",
    "section": "",
    "text": "A key feature of this course is that students should be using their own data whenever possible. This is critical to forging a learning experience that is customized to each student’s aspirations and the eccentricities of their chosen research domain. This assignment begins the process of helping you identify the data sets with which you want to work, and aligns with the notion of understanding the concepts of Data Semantics and Data Abstraction."
  },
  {
    "objectID": "posts/A2-YourData/index.html#assignment",
    "href": "posts/A2-YourData/index.html#assignment",
    "title": "ASSIGNMENT 2 - Your Data.",
    "section": "ASSIGNMENT",
    "text": "ASSIGNMENT\nThe basic structure of this assignment is for you to identify, import, describe, and host a data set. I’ll break down the specifics for each of these actions below.\n\nIdentify a Data Set\nThe main criteria is that the data set has to matter to you in some way. Often, this will mean that it is your data set. It was collected by you and has a central role in your current or past graduate research. Awesome! Another scenario is that the data you want to use comes from your current job. Maybe it isn’t part of a research project, but you are motivated to learn how to better visualize the data or you are very interested in learning more about it. Also Awesome!\nSome of you might not have your own data. Perhaps you have just started your graduate training. Maybe your job doesn’t yet have data that you need to work with. No Problem!\nIt is perfectly fine to find publicly available data sets online. As long as the data set is interesting to you! You just need to make sure that the data:\n\nAre publicly available.\nAre not restricted by some kind of license or copyright.\nDo not contain private information.\nAre not covered by HIPPA, FERPA, CMMC, or other federal regulations related to data.\n\nIf you need help finding a data set, just let me know.\nSome fun potential categories for data sources include:\n\nSports Analytics from your favorite sport or team.\nPublicly available genomics data bases.\nKeggle.\nThe movie data base.\nClassic data sets from your field.\n\n\n\nImport the Data Set\nThis one is probably straightforward if your data set comes from your own research and lives on your local hard drive already.\n\n\nDescribe the Data Set\nThis is the bulk of the assignment. I want you to use the framework described in Dr. Munzner’s textbook to understand your data set and describe it to someone who is unfamiliar with your work. The basis of this approach is descibed in this lecture. In addition, this figure from the textbook summarizes the kinds of data types, data set types, and attribute types you might have in your data:\n\n\n\nBONUS OBJECTIVE: Host your Data Set\nUltimately, we are moving toward each of you hosting your assignments within an online repository that can serve as your data science portfolio. For this course, we are going to assume this is GitHub. At the very least, I want everyone to create (or dust off and log in to) your own GitHub account. We’ll try to use this assignment to set up a project repository, and perhaps even a simple web site using GitHub pages."
  },
  {
    "objectID": "posts/A2-YourData/index.html#resources",
    "href": "posts/A2-YourData/index.html#resources",
    "title": "ASSIGNMENT 2 - Your Data.",
    "section": "RESOURCES",
    "text": "RESOURCES\nA YouTube Video from Posit on Building your Data Science Portfolio\nTidyTuesday\nA fun Spotify example from TidyTuesday by Kaylin Pavlik.\nBarrie attempts this assignment in Tutorial 4."
  },
  {
    "objectID": "posts/T1-Lit-Prog/index.html",
    "href": "posts/T1-Lit-Prog/index.html",
    "title": "TUTORIAL 1 - Literate Programming",
    "section": "",
    "text": "Learning new tools is hard. Plowing though the tomes of the Data Science Mythos is hard. Perhaps this tutorial will guide you through the mind shattering truths of… LITERATE PROGRAMMING."
  },
  {
    "objectID": "posts/T1-Lit-Prog/index.html#intro-to-quarto",
    "href": "posts/T1-Lit-Prog/index.html#intro-to-quarto",
    "title": "TUTORIAL 1 - Literate Programming",
    "section": "",
    "text": "Learning new tools is hard. Plowing though the tomes of the Data Science Mythos is hard. Perhaps this tutorial will guide you through the mind shattering truths of… LITERATE PROGRAMMING."
  },
  {
    "objectID": "posts/L1-Intro/index.html#who-am-i",
    "href": "posts/L1-Intro/index.html#who-am-i",
    "title": "LECTURE 1 - INTRO",
    "section": "WHO AM I?",
    "text": "WHO AM I?\nBarrie Robison\nDepartment of Biological Sciences\nInstitute for Interdisicplinary Data Sciences\nPolymorphic Games\nUniversity of Idaho"
  },
  {
    "objectID": "posts/L1-Intro/index.html#who-are-you",
    "href": "posts/L1-Intro/index.html#who-are-you",
    "title": "LECTURE 1 - INTRO",
    "section": "WHO ARE YOU?",
    "text": "WHO ARE YOU?\n“…The course is designed to be”discipline agnostic” - each student is encouraged to use data sets that they deem important / interesting. The goal is to have students learn how to develop visualizations that are relevant to their own disciplinary interests…”\nBriefly:\n\nYour name\nYour discipline\nYour degree progress\nYour technical proficiency with data visualization"
  },
  {
    "objectID": "posts/L1-Intro/index.html#course-summary",
    "href": "posts/L1-Intro/index.html#course-summary",
    "title": "LECTURE 1 - INTRO",
    "section": "COURSE SUMMARY",
    "text": "COURSE SUMMARY\nStudents completing this course will be able to:\n\n\nDescribe and manipulate tabular, network, and spatial data; transform these data into a form suitable for visualization.\nMake effective data visualization design choices related to marks and channels, spatial arrangement, and components of color.\nDesign effective data visualizations for tabular, network, and spatial data with quantitative and categorical attributes.\nImplement their data visualization designs using existing tools in R (or other toolkits preferred by the student).\nExplain whether a visual encoding is perceptually appropriate for a specific combination of task and data.\nDemonstrate their skills with at least two novel visualizations suitable suitable for inclusion in an online Data Science Portfolio.\n\nThe course materials are located on Canvas and the course website."
  },
  {
    "objectID": "posts/L1-Intro/index.html#visualization",
    "href": "posts/L1-Intro/index.html#visualization",
    "title": "LECTURE 1 - INTRO",
    "section": "VISUALIZATION",
    "text": "VISUALIZATION\nComputers provide visual representations of datasets designed to help people carry out tasks more effectively.\nTamara Munzner\nDepartment of Computer Science\nInfoVis Group\nUniversity of British Columbia"
  },
  {
    "objectID": "posts/L1-Intro/index.html#the-human",
    "href": "posts/L1-Intro/index.html#the-human",
    "title": "LECTURE 1 - INTRO",
    "section": "THE HUMAN",
    "text": "THE HUMAN\nWhy have a human in the loop?\nComputer-based visualization systems provide visual representations of datasets designed to help people carry out tasks more effectively.\n\nWe don’t need visualization when a trusted fully automatic solution exists.\nVisualization is suitable when there is a need to augment human capabilities rather than replace people with computational decision-making methods."
  },
  {
    "objectID": "posts/L1-Intro/index.html#when-to-visualize",
    "href": "posts/L1-Intro/index.html#when-to-visualize",
    "title": "LECTURE 1 - INTRO",
    "section": "WHEN TO VISUALIZE",
    "text": "WHEN TO VISUALIZE\nVisualization is useful when:\n\n\nThe analysis problem is ill-specified and we don’t know exactly what questions to ask in advance.\nWe are interested in long-term use for end users (ex: exploratory analysis of scientific data).\nWe are presenting known results (ex: DATA JOURNALISM - New York Times Upshot).\nWe need a stepping stone to assess requirements before developing models.\nDevelopers of an automatic solution want to refine & determine parameters.\nWe need to help end users of automatic solutions verify and build trust."
  },
  {
    "objectID": "posts/L1-Intro/index.html#the-representation",
    "href": "posts/L1-Intro/index.html#the-representation",
    "title": "LECTURE 1 - INTRO",
    "section": "THE REPRESENTATION",
    "text": "THE REPRESENTATION\nComputer-based visualization systems provide visual representations of datasets designed to help people carry out tasks more effectively.\nEXTERNAL REPRESENTATIONS: Replace cognition with perception."
  },
  {
    "objectID": "posts/L1-Intro/index.html#why-depend-on-vision",
    "href": "posts/L1-Intro/index.html#why-depend-on-vision",
    "title": "LECTURE 1 - INTRO",
    "section": "WHY DEPEND ON VISION?",
    "text": "WHY DEPEND ON VISION?\nComputer-based visualization systems provide visual representations of datasets designed to help people carry out tasks more effectively.\n\n\nThe human visual system is a high-bandwidth channel to the brain.\nOverview is possible due to background processing, providing the subjective experience of seeing everything simultaneously.\nSignificant processing occurs in parallel and pre-attentively.\nWhat about sound? lower bandwidth and different semantics, overview not supported, subjective experience of sequential stream.\nWhat about touch/haptics? impoverished record/replay capacity, only very low-bandwidth communication thus far.\nWhat about taste, smell? no viable record/replay devices."
  },
  {
    "objectID": "posts/L1-Intro/index.html#why-represent-all-the-data",
    "href": "posts/L1-Intro/index.html#why-represent-all-the-data",
    "title": "LECTURE 1 - INTRO",
    "section": "WHY REPRESENT (ALL THE) DATA?",
    "text": "WHY REPRESENT (ALL THE) DATA?\nComputer-based visualization systems provide visual representations of datasets designed to help people carry out tasks more effectively.\n\n\nsummaries lose information\ndetails matter\nconfirm expected and find unexpected patterns\nassess validity of statistical model\nANSCOMBE’S QUARTET is a fun example that we shall use to illustrate these points!"
  },
  {
    "objectID": "posts/L1-Intro/index.html#anscombes-quartet",
    "href": "posts/L1-Intro/index.html#anscombes-quartet",
    "title": "LECTURE 1 - INTRO",
    "section": "ANSCOMBE’S QUARTET",
    "text": "ANSCOMBE’S QUARTET\n\n\n\n\nCode\nlibrary(ggplot2)\nlibrary(grid)\nlibrary(gridExtra)\nlibrary(datasets)\nlibrary(tidyverse)\nlibrary(dplyr)\ndatasets::anscombe\n\n\n   x1 x2 x3 x4    y1   y2    y3    y4\n1  10 10 10  8  8.04 9.14  7.46  6.58\n2   8  8  8  8  6.95 8.14  6.77  5.76\n3  13 13 13  8  7.58 8.74 12.74  7.71\n4   9  9  9  8  8.81 8.77  7.11  8.84\n5  11 11 11  8  8.33 9.26  7.81  8.47\n6  14 14 14  8  9.96 8.10  8.84  7.04\n7   6  6  6  8  7.24 6.13  6.08  5.25\n8   4  4  4 19  4.26 3.10  5.39 12.50\n9  12 12 12  8 10.84 9.13  8.15  5.56\n10  7  7  7  8  4.82 7.26  6.42  7.91\n11  5  5  5  8  5.68 4.74  5.73  6.89\n\n\n\nAnscombe’s Quartet\nThe four x-y pairs have identical summary statistics.\n\n\nCode\ntidy_anscombe &lt;- anscombe %&gt;%\n pivot_longer(cols = everything(),\n              names_to = c(\".value\", \"set\"),\n              names_pattern = \"(.)(.)\")\ntidy_anscombe_summary &lt;- tidy_anscombe %&gt;%\n  group_by(set) %&gt;%\n  summarise(across(.cols = everything(),\n                   .fns = lst(min,max,median,mean,sd,var),\n                   .names = \"{col}_{fn}\"))\n#&gt; `summarise()` ungrouping output (override with `.groups` argument)\n\nvars&lt;-c(\"set\", \"x_mean\", \"x_var\",  \"y_mean\", \"y_var\")\nthing&lt;- as.data.frame(tidy_anscombe_summary[vars])\nknitr::kable(thing)\n\n\n\n\n\nset\nx_mean\nx_var\ny_mean\ny_var\n\n\n\n\n1\n9\n11\n7.500909\n4.127269\n\n\n2\n9\n11\n7.500909\n4.127629\n\n\n3\n9\n11\n7.500000\n4.122620\n\n\n4\n9\n11\n7.500909\n4.123249"
  },
  {
    "objectID": "posts/L1-Intro/index.html#viz-matters",
    "href": "posts/L1-Intro/index.html#viz-matters",
    "title": "LECTURE 1 - INTRO",
    "section": "VIZ MATTERS",
    "text": "VIZ MATTERS\n\n\nCode\nggplot(tidy_anscombe,\n       aes(x = x,\n           y = y)) +\n  geom_point() +\n  geom_point(data = tidy_anscombe_summary, aes(x=x_mean, y = y_mean, color = \"red\", size = 5),\n             show.legend = FALSE)+\n  facet_wrap(~set) +\n  geom_smooth(method = \"lm\", se = FALSE)\n\n\n\n\nLearn more: TIDY ANSCOMBE"
  },
  {
    "objectID": "posts/L1-Intro/index.html#resource-limitations",
    "href": "posts/L1-Intro/index.html#resource-limitations",
    "title": "LECTURE 1 - INTRO",
    "section": "RESOURCE LIMITATIONS",
    "text": "RESOURCE LIMITATIONS\nVisualization designers must take into account three very different kinds of resource limitations:\n\nLimitations of computers.\nLimitations of humans.\nLimitations of displays."
  },
  {
    "objectID": "posts/L1-Intro/index.html#computational-limits",
    "href": "posts/L1-Intro/index.html#computational-limits",
    "title": "LECTURE 1 - INTRO",
    "section": "COMPUTATIONAL LIMITS",
    "text": "COMPUTATIONAL LIMITS\nCPU time\nSystem Memory"
  },
  {
    "objectID": "posts/L1-Intro/index.html#display-limits",
    "href": "posts/L1-Intro/index.html#display-limits",
    "title": "LECTURE 1 - INTRO",
    "section": "DISPLAY LIMITS",
    "text": "DISPLAY LIMITS\nPixels are precious and are the most constrained resource.\n\nInformation Density: ratio of space used to encode information vs unused whitespace.\nThere is a tradeoff between clutter and wasting space.\nDesigner must find the sweet spot between dense and sparse."
  },
  {
    "objectID": "posts/L1-Intro/index.html#human-limits",
    "href": "posts/L1-Intro/index.html#human-limits",
    "title": "LECTURE 1 - INTRO",
    "section": "HUMAN LIMITS",
    "text": "HUMAN LIMITS\n\nTime\nMemory\nAttention\n\n\n\n\n\nCANVAS…HOME"
  },
  {
    "objectID": "posts/Certificate/index.html",
    "href": "posts/Certificate/index.html",
    "title": "CERTIFICATE",
    "section": "",
    "text": "Learn how to think about, organize, analyze, and visualize data. Communicate data-driven insights to technical and lay audiences."
  },
  {
    "objectID": "posts/Certificate/index.html#overview",
    "href": "posts/Certificate/index.html#overview",
    "title": "CERTIFICATE",
    "section": "OVERVIEW",
    "text": "OVERVIEW\nWe live in an increasingly data-driven world. Basic data literacy and data science skills are becoming central to virtually every industry. Yet, limited opportunities exist to gain these skills without an advanced background in math and computer science. To address this workforce development need, we propose a competitively valued on-line graduate certificate in the Professional Applications in Data Science. The certificate is designed to offer rigorous training in the foundations of data science to anyone with a bachelor’s degree. Participants will learn how to think about, organize, analyze, and visualize data, and communicate data driven insights to diverse audiences. The curriculum emphasizes the use of data sets drawn from each student’s individual discipline, aligning the certificate’s workforce development impacts with the University of Idaho’s land grant mission.\n\nValue Proposition:\nThe graduate certificate in Professional Applications in Data Science will provide unique value to UI constituencies by:\n\nAligning data science training with fields of nascent demand that are part of our land grant mission, including Agriculture, Natural Resources, and Education.\nRequiring a digital data science portfolio with which students can demonstrate their proficiencies to potential employers.\nEmphasizing training in data communication - including verbal presentation and data visualization - two components of data science that are underrepresented in competing certificates.\nFilling a growing workforce development gap by offering a unique data science certificate that is appropriate for professionals with a bachelor’s degree who do not have a rigorous background in mathematics, statistics, or computer science.\n\n\n\nIntended Audience:\nThis certificate leverages the University of Idaho’s interdisciplinary culture to provide integrative training in the foundations of data science. It is intended for:\n\nWorking professionals with a bachelor’s degree whose career increasingly involves the generation, management, analysis, and visualization of large data sets. The certificate is appropriate for professionals in STEM fields, Health Care, Business, Government, Education, Journalism, Athletics, Natural Resources, and Agriculture.\nGraduate students in programs outside of the core technical disciplines of data science (statistics, math, engineering, or computer science). The certificate will complement disciplinary research methods courses with training in data management, visualization, and communication.\nUndergraduates at the UI who wish to incorporate data science training into their degree and graduate with a Bachelor’s degree and a graduate certificate.\n\n\n\nStudent Learning Outcomes:\nUpon completion of the certificate, students will be able to:\n\nUse open-source software to reproducibly manage, analyze, and visualize large, complex, and noisy data sets.\nPractice high quality and ethical data stewardship.\nUnderstand and execute data exploration.\nEffectively communicate data driven insights to experts and non-experts.\nDemonstrate their skills with an online portfolio of analyses and visualizations relevant to their field of specialization."
  },
  {
    "objectID": "posts/Certificate/index.html#curriculum",
    "href": "posts/Certificate/index.html#curriculum",
    "title": "CERTIFICATE",
    "section": "CURRICULUM",
    "text": "CURRICULUM\n\nPrerequisites:\nA Bachelor’s degree OR the student has senior standing and is enrolled in a bachelor’s degree program at the University of Idaho.\n\n\nCertificate Requirements (12 Credits Total)\n\n\n\n\n\n\n\n\n\n\n\n\nCourse\nName\nCredits\nPrerequisites\nSchedule\n\n\n\n\nINTR 509\nIntroduction to Applied Data Science\n3\nBS degree or permission\nSpring and asynchronous online\n\n\nBCB 551\nCommunicating with Data\n2\nINTR 509 or BS degree or permission\nFall and asynchronous online\n\n\nBCB 520\nData Visualization\n3\nSTAT 251 or INTR 509 or permission\nSpring and asynchronous online\n\n\nBCB 522\nData Science Portfolio\n1\nINTR 509 and BCB 520 (Data Viz)\nAsynchronous online\n\n\nElective\nVaries\n3\nVaries\nVaries\n\n\n\n\n\nnote: Courses designated with “BCB 5XX” are new courses that will be offered in the 2023-24 academic year\n\n\nCourse Descriptions\n\nINTR 509 Introduction to Applied Data Science (3 credits)\nIn person (spring) and asynchronous online.\nStudents are provided a foundation for “thinking with data” through the introduction of computational, statistical, and data literacy skills. This includes the selection, collection, cleaning, management, descriptive analysis, and exploratory analysis of a dataset unique to their professional interests using modern computing languages. This course is taught by Dr. Michael Overton.\n\n\nBCB 521 Communicating with Data (2 credits)\nIn person (fall) and asynchronous online.\nStudents are taught writing and presentation skills to improve their communication of data-driven insights to specialist and lay audiences. The course emphasizes reproducible research practices, including literate programming (R Markdown) and version control (GitHub). Course content includes the conceptual foundations of communicating with data along with written and verbal communication assignments using data sets individualized to each student’s interest.\nText: Nolan and Stoudt. 2021. Communicating with data: The art of writing for data science. Oxford University Press.\nPrerequisites: INTR 509 OR A BS degree OR permission.\n\n\nBCB 520 Data Visualization (3 credits)\nIn person (spring) and asynchronous online\nThis course covers the conceptual foundations of data visualization and design. Students will learn how visualization design choices related to marks and channels, color, and spatial arrangement interact with the human perceptual system. The course considers tabular, network, and spatial data, and students will implement visualizations in R.\nText: Munzner. 2014. Visualization Analysis & Design. CRC Press.\nPrerequisites: INTR 509 OR A BS degree OR Stat 251 OR Permission.\n\n\nBCB 522 Online Portfolio (1 credit)\nAsynchronous online\nThis course provides feedback, review, and approval of the student’s online data science portfolio. This portfolio is intended to represent the body of work accumulated by the student over the course of the certificate. It should contain examples of novel data products (such as FAIR data sets), analyses, and visualizations. All elements of the portfolio will be hosted online (likely in a GitHub repository or professional website), be open source, and demonstrate best practices of literate programming and reproducible research.\n\n\nElectives:\nThe certificate allows each student to customize their training by choosing a 3-credit graduate elective.\nFor students seeking foundational training who have not already taken Stat 431 or its equivalent, we recommend Stat 431 or a 3-credit graduate level disciplinary research methods course.\nFor students seeking to add the certificate to an existing degree at UI, or students who already have some advanced technical training, additional electives are possible. Note that many of these optional electives have substantial disciplinary pre-requisites. Not all electives are available in an online format.\n\n\nChoose one of the following:\n\n\n\n\n\nCourse\nName\nCredits\nPrerequisites\n\n\n\n\nAVS 531\nPractical Methods in Analyzing Animal Science Experiments\n3\n400-level statistics course\n\n\nBE 521\nImage Processing and Computer Vision\n3\n(BE 242 and MATH 275) or permission\n\n\nBE 541\nInstrumentation and Measurements\n3\nENGR 240; Coreqs: STAT 301\n\n\nBIOL 526\nSystems Biology\n3\n(BIOL 115, BIOL 115L and MATH 170) or permission of instructor\n\n\nBIOL 545\nPhylogenetics\n3\nPLSC 205 or BIOL 213 and BIOL 310\n\n\nBIOL 549\nComputer Skills for Biologists\n3\nBIOL 310 and STAT 251 or STAT 301; or Permission\n\n\nBIOL 563\nMathematical Genetics\n3\nMATH 160 or MATH 170 and STAT 251 or STAT 301\n\n\nCE 526\nAquatic Habitat Modeling\n3\nA minimum grade of ‘C’ or better is required for all pre/corequisites; Prereqs: CE 322 and CE 325 or BE 355; or Permission\n\n\nCE 579\nSimulation of Transportation Systems\n3\nPermission\n\n\nCS 511\nParallel Programming\n3\nCS 395\n\n\nCS 574\nDeep Learning\n3\n(CS 121 or MATH 330) and STAT 301\n\n\nCS 570\nArtificial Intelligence\n3\nCS 210\n\n\nCS 572\nEvolutionary Computation\n3\nCS 211\n\n\nCS 575\nMachine Learning\n3\nCS 210\n\n\nCS 577\nPython for Machine Learning\n3\n(CS 121 or MATH 330) and STAT 301\n\n\nCS 578\nNeural Network Design\n3\nPermission\n\n\nCS 579\nData Science\n3\nMATH 330 or Permission\n\n\nCS 589\nSemantic Web and Open Data\n3\nCS 360 or CS 479 or CS 579\n\n\nCTE 519\nDatabase Applications and Information Management\n3\nNA\n\n\nCYB 520\nDigital Forensics\n3\nCYB 310\n\n\nED 571\nIntroduction to Quantitative Research\n3\nGraduate standing\n\n\nED 584\nUnivariate Quantitative Research in Education\n3\nED 571\n\n\nED 587\nMultivariate Quantitative Analysis in Education\n3\nED 584 or Permission\n\n\nED 589\nTheoretical Applications and Designs of Qualitative Research\n3\nED 574 or Permission\n\n\nED 590\nData Analysis and Interpretation of Qualitative Research\n3\nED 574 and ED 589\n\n\nED 591\nIndigenous and Decolonizing Research Methods\n3\nNA\n\n\nED 592\nDecolonizing, Indigenous, and Action-Based Research Methods\n3\nNA\n\n\nED 595\nSurvey Design for Social Science Research\n3\nRecommended Preparation: Foundations of Research course at graduate level.\n\n\nEDAD 570\nMethods of Educational Research\n3\nNA\n\n\nENT 504\nApplied Bioinformatics\n3\nPermission\n\n\nENVS 511\nData Wizardry in Environmental Sciences\n3\nSTAT 251\n\n\nENVS 551\nResearch Methods in the Environmental Social Sciences\n3\nOne course or experience in basic statistics or Instructor Permission\n\n\nFOR 514\nForest Biometrics\n3\nSTAT 431 or equivalent\n\n\nFOR 535\nRemote Sensing of Fire\n3\nFOR 375 or permission\n\n\nGEOG 507\nSpatial Statistics and Modeling\n3\nSTAT 431 or permission\n\n\nGEOG 583\nRemote Sensing/GIS Integration\n3\nCoreqs: GEOG 385 or equivalent.\n\n\nMath 538\nStochastic Models\n3\nMATH 451 or Permission\n\n\nMIS 555\nData Management for Big Data\n3\nNA\n\n\nNRS 578\nLidar and optical remote sensing analysis using open-source software\n3\nSTAT251 & WLF370 or STAT427 and NRS/FOR 472 or equivalent/instructor permission\n\n\nPOLS 558\nResearch Methods for Local Government and Community Administration\n3\nSTAT 251\n\n\nREM 507\nLandscape and Habitat Dynamics\n3\nPermission; Recommended Preparation: courses in ecology, statistics, and GIS.\n\n\nStat 431\nStatistical Analysis\n3\nSTAT 251 or STAT 301\n\n\nSTAT 514\nNonparametric Statistics\n3\nSTAT 431\n\n\nSTAT 516\nApplied Regression Modeling\n3\nSTAT 431\n\n\nStat 517\nStatistical Learning and Predictive Modeling\n3\nSTAT 431\n\n\nStat 519\nMultivariate Analysis\n3\nSTAT 431 or equivalent.\n\n\nSTAT 535\nIntroduction to Bayesian Statistics\n3\nSTAT 431\n\n\nSTAT 555\nStatistical Ecology\n3\nMATH 451 or Permission\n\n\nStat 565\nComputer Intensive Methods\n3\n STAT 451, STAT 452, MATH 330, and computer programming experience or Permission\n\n\nWLF 552\nEcological Modeling\n3\nMATH 175 and FOR 221 or Permission.\n\n\nWLF 555\nStatistical Ecology\n3\nMATH 451 or permission\n\n\nWR 552\nWater Economics and Policy\n3\nAGEC 301 or AGEC 302, or ECON 351 or ECON 352, or by permission"
  },
  {
    "objectID": "posts/Certificate/index.html#general-university-requirements",
    "href": "posts/Certificate/index.html#general-university-requirements",
    "title": "CERTIFICATE",
    "section": "GENERAL UNIVERSITY REQUIREMENTS",
    "text": "GENERAL UNIVERSITY REQUIREMENTS\nIn addition to the requirements specified in this document, the certificate would be subject to all UI Policies regarding Graduate Certificates."
  },
  {
    "objectID": "posts/A1-Lit-Prog/index.html",
    "href": "posts/A1-Lit-Prog/index.html",
    "title": "ASSIGNMENT 1 - Fun with literate programming.",
    "section": "",
    "text": "The idea of Literate Programming is that source code that is executed as part of the program’s purpose is interspersed with documentation that describes the program’s logic. The concept of literate programming was first articulated by David Knuth in 1984. You know… back when music was good? Modern Data Science leans pretty heavily on literate programming, and to be honest, there aren’t very many good arguments as to why you WOULDN’T want to implement this approach in your own work. Bearing this in mind, we will adopt this framework for most of the activities, exercises, and assignments in this course. All of us will benefit by practicing these skills."
  },
  {
    "objectID": "posts/A1-Lit-Prog/index.html#summary",
    "href": "posts/A1-Lit-Prog/index.html#summary",
    "title": "ASSIGNMENT 1 - Fun with literate programming.",
    "section": "",
    "text": "The idea of Literate Programming is that source code that is executed as part of the program’s purpose is interspersed with documentation that describes the program’s logic. The concept of literate programming was first articulated by David Knuth in 1984. You know… back when music was good? Modern Data Science leans pretty heavily on literate programming, and to be honest, there aren’t very many good arguments as to why you WOULDN’T want to implement this approach in your own work. Bearing this in mind, we will adopt this framework for most of the activities, exercises, and assignments in this course. All of us will benefit by practicing these skills."
  },
  {
    "objectID": "posts/A1-Lit-Prog/index.html#literate-programming-publishing-systems",
    "href": "posts/A1-Lit-Prog/index.html#literate-programming-publishing-systems",
    "title": "ASSIGNMENT 1 - Fun with literate programming.",
    "section": "LITERATE PROGRAMMING PUBLISHING SYSTEMS",
    "text": "LITERATE PROGRAMMING PUBLISHING SYSTEMS\nI’m trying to keep this course as technology agnostic as I can. The idea is that you should be practicing and building competencies in the languages and algorithms that are most useful to you. Who am I to tell you to use R instead of Python? If you have skills in a particular language I encourage you to keep using that during this course. That being said, I am going to work the examples using R and R Studio, and I will (mostly) use Quarto as the literate programming framework.\nIf all of this is new to you, no problem. Just follow along in R and Quarto and start your skill building journey with those languages.\nIf you are a Python person, great! Quarto can accommodate that language as well. If you have another preference for literate programming, such as sticking with R Markdown until the Quarto bugs are fixed, that is great. Find the framework and tools that work for you, and practice, practice, practice!\n\nQuarto\nAn open source publishing system that allows you to create websites, documents, blogs, books, publications, presentations, and more while using R, Python, Julia, or Observable. Quarto is intended to be the more functional successor of R Markdown. I intend to use Quarto for most of my work in this course.\n\n\nR Markdown\nAnother publishing system for creating all the things … websites, slides, manuscripts, dashboards, etc. While most people (including me!) instinctively think of R and Python within R Markdown, the list of supported language engines is pretty extensive.\n\nnames(knitr::knit_engines$get())\n\n [1] \"awk\"       \"bash\"      \"coffee\"    \"gawk\"      \"groovy\"    \"haskell\"  \n [7] \"lein\"      \"mysql\"     \"node\"      \"octave\"    \"perl\"      \"php\"      \n[13] \"psql\"      \"Rscript\"   \"ruby\"      \"sas\"       \"scala\"     \"sed\"      \n[19] \"sh\"        \"stata\"     \"zsh\"       \"asis\"      \"asy\"       \"block\"    \n[25] \"block2\"    \"bslib\"     \"c\"         \"cat\"       \"cc\"        \"comment\"  \n[31] \"css\"       \"ditaa\"     \"dot\"       \"embed\"     \"eviews\"    \"exec\"     \n[37] \"fortran\"   \"fortran95\" \"go\"        \"highlight\" \"js\"        \"julia\"    \n[43] \"python\"    \"R\"         \"Rcpp\"      \"sass\"      \"scss\"      \"sql\"      \n[49] \"stan\"      \"targets\"   \"tikz\"      \"verbatim\"  \"ojs\"       \"mermaid\""
  },
  {
    "objectID": "posts/A1-Lit-Prog/index.html#languages-and-toolsets",
    "href": "posts/A1-Lit-Prog/index.html#languages-and-toolsets",
    "title": "ASSIGNMENT 1 - Fun with literate programming.",
    "section": "LANGUAGES AND TOOLSETS",
    "text": "LANGUAGES AND TOOLSETS\nThere are quite a few, but the five that seemed to keep coming up as I prepped this course are:\n\nR\nA very powerful open source framework for statistical computing and graphics. R has a lot of base functionality, and its capabilities are increased by 100 fold with packages created by R users. Packages are the core units of R code. I’m going to use R for the vast majority of demonstrations in this course.\n\n\nPython\nPython is an open source general purpose programming language. It wasn’t developed just for statistical computing or data science, and people use this language for tons of different applications. There is no denying it has become a very powerful language for data science and data visualization.\n\n\nTableau\nTableau is proprietary software that is very powerful for creating beautiful and functional data visualizations. It can integrate with all sorts of data sources and is used a lot for analytics, especially in the business world. The downsides (that occur to me at least) are that it costs money, it is not open source, and is more of a one-trick-pony than the programming languages on this list.\n\n\nJavascript\nJavascript has been around for about 25 years, and is (I think) the world’s most popular programming language. Along with HTML and CSS, Javascript drives pretty much the entire internet. I mention Javascript here because it has the D3 library, which can create super cool interactive data visualizaitons. In my experience, the learning curve with Javascript and D3 was pretty steep. I bought a book about it once, but just haven’t been able to allocate the amount of time necessary to really start using it. Check out the gallery of examples. Amazing!\n\n\nObservable / D3\nObservable is a set of extensions to Javascript that features something called reactive runtime. This means that the code blocks are executed and compiled as they are written, and changes are implemented instantaneously. Observable is pretty great for data exploration, and is well supported by Quarto. In addition, you can use the Observable JS libraries in Quarto to access D3. We’ll use some of these tools in this course, especially when we start considering interactivity."
  },
  {
    "objectID": "posts/A1-Lit-Prog/index.html#assignment",
    "href": "posts/A1-Lit-Prog/index.html#assignment",
    "title": "ASSIGNMENT 1 - Fun with literate programming.",
    "section": "ASSIGNMENT",
    "text": "ASSIGNMENT\nAfter that long introduction, I suppose you are wondering what I want you to actually DO today.\nWell, I want you to set up your publishing system and preferred language on your computer. Then I want you to recreate the classic figure from Anscombe’s Quartet.\nNow, you might be asking…\n“How am I supposed to do that? You haven’t taught me how to do anything yet!”\nHere is the dirty little secret of modern education.\nThe Internet Exists.\nWhile I could use up an entire 90 minute lecture telling you how to:\n\nDownload and install R, R-Studio, and Quarto (included by default with R-Studio).\nCreate a Quarto document that will publish in the .html format\nInstall the R packages you will need\nTidy up the Anscombe’s Quartet data\nCalculate the summary statistics for each x y pair\nMake a nice little plot…\n\nI’m not going to do that.\nInstead, I want you to use the resources I point towards, or other resources that make more sense to you, to figure out how to do those things."
  },
  {
    "objectID": "posts/A1-Lit-Prog/index.html#resources",
    "href": "posts/A1-Lit-Prog/index.html#resources",
    "title": "ASSIGNMENT 1 - Fun with literate programming.",
    "section": "RESOURCES",
    "text": "RESOURCES\nTidyverse and Anscombe’s Quartet\nHandy cheat-sheets for many different R packages\nTutorial 1 - Literate Programming\nTutorial 2 - Literate Programming and Anscombe’s Quartet\nTutorial 3 - Python"
  },
  {
    "objectID": "posts/A3-PrototypeVizPortfolio/index.html",
    "href": "posts/A3-PrototypeVizPortfolio/index.html",
    "title": "ASSIGNMENT 3",
    "section": "",
    "text": "Enough with the theory and conceptual mumbo jumbo! Let’s get down to making a visualization and posting it somewhere for all the world to see! The basic idea of this assignment is to set up a repository that will serve as an experimental portfolio, and then create your first novel visualization element inside the portfolio. Its gonna be fun! Or at least educational…"
  },
  {
    "objectID": "posts/A3-PrototypeVizPortfolio/index.html#summary",
    "href": "posts/A3-PrototypeVizPortfolio/index.html#summary",
    "title": "ASSIGNMENT 3",
    "section": "",
    "text": "Enough with the theory and conceptual mumbo jumbo! Let’s get down to making a visualization and posting it somewhere for all the world to see! The basic idea of this assignment is to set up a repository that will serve as an experimental portfolio, and then create your first novel visualization element inside the portfolio. Its gonna be fun! Or at least educational…"
  },
  {
    "objectID": "posts/A3-PrototypeVizPortfolio/index.html#assignment",
    "href": "posts/A3-PrototypeVizPortfolio/index.html#assignment",
    "title": "ASSIGNMENT 3",
    "section": "ASSIGNMENT",
    "text": "ASSIGNMENT\nThis assignment has two parts. The first part is technical. We’ll set up a Quarto Blog project as a new repository in your GitHub account. Then you’ll be a Blogger! Prestigious! The second part should be more fun. We are going to create your first Blog post as a visualization that explores an ACTION - TARGET pair relevant to your data set from Assignment 2."
  },
  {
    "objectID": "posts/A3-PrototypeVizPortfolio/index.html#part-1-technical-sorcery",
    "href": "posts/A3-PrototypeVizPortfolio/index.html#part-1-technical-sorcery",
    "title": "ASSIGNMENT 3",
    "section": "PART 1 TECHNICAL SORCERY",
    "text": "PART 1 TECHNICAL SORCERY\n\n1A - Create your BLOG project.\nHopefully by now you have created / dusted off / logged in to your GitHub account. Go ahead and log in to your account on the web and leave it open in a tab in your browser. There is a really great video about the next few steps (also linked below in RESORUCES) from Posit, but I’m giving you the condensed version here.\n\nFire up RStudio.\nGo to File-&gt;New Project and then select NEW DIRECTORY.\nNow select QUARTO BLOG.\nYou are going to create a the project in a new working directory. It is best practice to put this in a senstible directory structure on your local hard drive where your other GitHub repositories also live. Here is what mine looks like:\n\n 4. I suggest making the directory name something informative, like BCB504Portfolio, but hey… If you want to call your repository HasturBoxerShorts I won’t stop you. 5. Most of you will select Knitr as your Engine, but Cody “Mr. Hacker McPythonPants” might select Jupyter. 6. Check Create a git repository. The other boxes are optional and we can talk more about them later. 7. Click CREATE PROJECT.\nNow you’ve got a BLOG template all set up! Ha Ha! Onward to Internet Fame!\n\n\n1B - Make the BLOG about you.\nWe won’t spend a ton of time here, because this will be an ongoing process. You’ll go and watch all those cool videos and tutorials this weekend to figure this out. But lets do a couple things.\n\nMaybe you should modify the about.qmd file so that your name is in there somewhere.\nMaybe you should modify the index.qmd file with a better title in the YAML header.\nMaybe you should navigate to the posts folder, open the Welcome to my blog folder, open index.qmd from that directory, and add a sentence or two.\n\n\n\n1C - Customize your first post.\n\nNavigate to the posts folder, open the post with code folder, and open index.qmd.\nReplace ALL of the content of index.qmd with the most recent version of your .qmd file from ASSIGNMENT 2. Keep the file name index.qmd. Save that file!\nMove your data files to the post with code folder.\nRender the index.qmd file from this folder. Hopefully it worked!\n\n\n\n1D - Render the BLOG as a website.\n\nIMPORTANT Open your _quarto.yml file and add output-dir: docs under project:\n\n\nThe indentations matter here.\n\nSave all the files you’ve modified.\nGo to the BUILD tab in the (probably) top right section of RStudio.\nClick RENDER WEBSITE.\nClick through your new Blog and see how it works!\n\n\n\n1E - Push to GitHub.\nThere are quite a few ways to do this part. I’m going to use GitHub Desktop, but those video will show you other ways.\n\nGo to GitHub Desktop.\nType some text in the summary box.\nClick COMMIT TO MASTER.\nClick PUSH ORIGIN.\nGo to your GitHub in your browser. You should see your new repository! Yay!\n\n\n\n1F - Make it a website with GitHub pages.\n\nIn your browser, click on your repository.\nGo to SETTINGS.\nSelect PAGES.\nSet the SOURCE option to Deploy from a branch.\nSet the BRANCH to master and the directory to docs\nDeploy that stuff and wait. Then visit your site!"
  },
  {
    "objectID": "posts/A3-PrototypeVizPortfolio/index.html#part-2-eldritch-visualization-ritual",
    "href": "posts/A3-PrototypeVizPortfolio/index.html#part-2-eldritch-visualization-ritual",
    "title": "ASSIGNMENT 3",
    "section": "PART 2 ELDRITCH VISUALIZATION RITUAL",
    "text": "PART 2 ELDRITCH VISUALIZATION RITUAL\n\n2A Define your ACTION - TARGET pair(s)\nIn [LECTURE 3] we discussed the concept of Task Abstraction in which you define the viz task that you want to help the user accomplish. This was represented as sets of ACTIONS that the user would perform (e.g. Discover, Present, Browse, Identify) on TARGETS related to the data set (e.g. Trends, Attributes, etc.).\nThink about one or two visualizations you wish to construct with your data, and try to define them in terms of ACTION - TARGET pairs. While you are at it, why don’t you update the index.qmd file of your BLOG POST with a new seciton at the bottom titled TASK ABSTRACTION, and put a sentence describing your visualizations and the ACTION - TARGET pairs they represent?\n\n\n2B Construct your Visualization\nLet’s get to work! Using whatever tools you can, code up your visualization in that new section of your BLOG post. You can check out how I approached this part in TUTORIAL 4."
  },
  {
    "objectID": "posts/A3-PrototypeVizPortfolio/index.html#resources",
    "href": "posts/A3-PrototypeVizPortfolio/index.html#resources",
    "title": "ASSIGNMENT 3",
    "section": "RESOURCES",
    "text": "RESOURCES\nA YouTube Video from Posit on Building your Data Science Portfolio\nTidyTuesday\nA fun Spotify example from TidyTuesday by Kaylin Pavlik.\nQuarto’s BLOG Documentation\nA YouTube Video from Posit on Building a BLOG with Quarto"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "BCB 521:: Communicating with Data",
    "section": "",
    "text": "This class will help students establish a core understanding of data visualization. We will consider how data type (including tabular, network, and spatial data) interacts with visualization task to guide design choices. Diverse types of visual encodings and how they relate to human perception will be presented, along with practical exercises using the R and Python programming languages. Upon completion of the course, students will understand WHY particular visualization approaches are effective for a given data set and HOW to implement those visualizations using the language of their choice. The course is designed to be “discipline agnostic” - each student is encouraged to use data sets that they deem important / interesting. The goal is to have students learn how to develop visualizations that are relevant to their own disciplinary interests.\n\n\nSYLLABUS\nBarrie’s GitHub\n\n\n\n\n\n\nThe Functional Art\nGGSIDE! A companion to ggplot for making side plots! COOL!\nAwesome Quarto: A potentially interesting repository of Quarto documents, talks, tools, examples, etc.\nThe MockUp Blog - TABLES! This blog post explores the R packages gt and gtextras which will help us up our table game!\nRiffomonas Project: Pat Schloss is a Professor at the University of Michigan. The Riffomonas Project is his Youtube channel, which has HUNDREDS of easy to follow and amazingly useful instructional videos on R, ggplot, version control, and literate programming.\nDr. Tamara Munzner’s Website: It isn’t fancy, but Dr. Munzner’s website has tons of resources from her textbook and the many data visualization courses she has offered. This includes recorded lectures that align directly with the chapters of the text, much like what we are using.\nCheat Sheets: So many visual guides for many R packages, including the tidyverse, ggplot, dplyr, etc.\nLearning Vis Tools: Teaching Data Visualization Tutorials An interesting paper for discussion as we forge the structure for this class."
  },
  {
    "objectID": "index.html#quick-links",
    "href": "index.html#quick-links",
    "title": "BCB 521:: Communicating with Data",
    "section": "",
    "text": "SYLLABUS\nBarrie’s GitHub"
  },
  {
    "objectID": "index.html#learning-resources",
    "href": "index.html#learning-resources",
    "title": "BCB 521:: Communicating with Data",
    "section": "",
    "text": "The Functional Art\nGGSIDE! A companion to ggplot for making side plots! COOL!\nAwesome Quarto: A potentially interesting repository of Quarto documents, talks, tools, examples, etc.\nThe MockUp Blog - TABLES! This blog post explores the R packages gt and gtextras which will help us up our table game!\nRiffomonas Project: Pat Schloss is a Professor at the University of Michigan. The Riffomonas Project is his Youtube channel, which has HUNDREDS of easy to follow and amazingly useful instructional videos on R, ggplot, version control, and literate programming.\nDr. Tamara Munzner’s Website: It isn’t fancy, but Dr. Munzner’s website has tons of resources from her textbook and the many data visualization courses she has offered. This includes recorded lectures that align directly with the chapters of the text, much like what we are using.\nCheat Sheets: So many visual guides for many R packages, including the tidyverse, ggplot, dplyr, etc.\nLearning Vis Tools: Teaching Data Visualization Tutorials An interesting paper for discussion as we forge the structure for this class."
  }
]